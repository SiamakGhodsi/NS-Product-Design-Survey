
@article{hayes_practical_2022,
	title = {A practical guide to multi-objective reinforcement learning and planning},
	volume = {36},
	issn = {1573-7454},
	url = {https://doi.org/10.1007/s10458-022-09552-y},
	doi = {10.1007/s10458-022-09552-y},
	abstract = {Real-world sequential decision-making tasks are generally complex, requiring trade-offs between multiple, often conflicting, objectives. Despite this, the majority of research in reinforcement learning and decision-theoretic planning either assumes only a single objective, or that multiple objectives can be adequately handled via a simple linear combination. Such approaches may oversimplify the underlying problem and hence produce suboptimal results. This paper serves as a guide to the application of multi-objective methods to difficult problems, and is aimed at researchers who are already familiar with single-objective reinforcement learning and planning methods who wish to adopt a multi-objective perspective on their research, as well as practitioners who encounter multi-objective decision problems in practice. It identifies the factors that may influence the nature of the desired solution, and illustrates by example how these influence the design of multi-objective decision-making systems for complex problems.},
	language = {en},
	number = {1},
	urldate = {2025-02-25},
	journal = {Auton Agent Multi-Agent Syst},
	author = {Hayes, Conor F. and Rădulescu, Roxana and Bargiacchi, Eugenio and Källström, Johan and Macfarlane, Matthew and Reymond, Mathieu and Verstraeten, Timothy and Zintgraf, Luisa M. and Dazeley, Richard and Heintz, Fredrik and Howley, Enda and Irissappane, Athirai A. and Mannion, Patrick and Nowé, Ann and Ramos, Gabriel and Restelli, Marcello and Vamplew, Peter and Roijers, Diederik M.},
	month = apr,
	year = {2022},
	keywords = {Artificial Intelligence, Multi-objective decision making, Multi-objective multi-agent systems, Multi-objective planning, Multi-objective reinforcement learning},
	pages = {26},
	}

@article{moaert_multi-objective_nodate,
	title = {Multi-{Objective} {Reinforcement} {Learning} using {Sets} of {Pareto} {Dominating} {Policies}},
	abstract = {Many real-world problems involve the optimization of multiple, possibly conﬂicting objectives. Multi-objective reinforcement learning (MORL) is a generalization of standard reinforcement learning where the scalar reward signal is extended to multiple feedback signals, in essence, one for each objective. MORL is the process of learning policies that optimize multiple criteria simultaneously. In this paper, we present a novel temporal diﬀerence learning algorithm that integrates the Pareto dominance relation into a reinforcement learning approach. This algorithm is a multi-policy algorithm that learns a set of Pareto dominating policies in a single run. We name this algorithm Pareto Q-learning and it is applicable in episodic environments with deterministic as well as stochastic transition functions. A crucial aspect of Pareto Q-learning is the updating mechanism that bootstraps sets of Q-vectors. One of our main contributions in this paper is a mechanism that separates the expected immediate reward vector from the set of expected future discounted reward vectors. This decomposition allows us to update the sets and to exploit the learned policies consistently throughout the state space. To balance exploration and exploitation during learning, we also propose three set evaluation mechanisms. These three mechanisms evaluate the sets of vectors to accommodate for standard action selection strategies, such as -greedy. More precisely, these mechanisms use multi-objective evaluation principles such as the hypervolume measure, the cardinality indicator and the Pareto dominance relation to select the most promising actions. We experimentally validate the algorithm on multiple environments with two and three objectives and we demonstrate that Pareto Q-learning outperforms current state-of-the-art MORL algorithms with respect to the hypervolume of the obtained policies. We note that (1) Pareto Q-learning is able to learn the entire Pareto front under the usual assumption that each state-action pair is suﬃciently sampled, while (2) not being biased by the shape of the Pareto front. Furthermore, (3) the set evaluation mechanisms provide indicative measures for local action selection and (4) the learned policies can be retrieved throughout the state and action space.},
	language = {en},
	author = {Moﬀaert, Kristof Van and Nowe, Ann},
	}

@inproceedings{yang_generalized_2019,
	title = {A {Generalized} {Algorithm} for {Multi}-{Objective} {Reinforcement} {Learning} and {Policy} {Adaptation}},
	volume = {32},
	url = {https://proceedings.neurips.cc/paper_files/paper/2019/hash/4a46fbfca3f1465a27b210f4bdfe6ab3-Abstract.html},
	abstract = {We introduce a new algorithm for multi-objective reinforcement learning (MORL) with linear preferences, with the goal of enabling few-shot adaptation to new tasks. In MORL, the aim is to learn policies over multiple competing objectives whose relative importance (preferences) is unknown to the agent. While this alleviates dependence on scalar reward design, the expected return of a policy can change significantly with varying preferences, making it challenging to learn a single model to produce optimal policies under different preference conditions. We propose a generalized version of the Bellman equation to learn a single parametric representation for optimal policies over the space of all possible preferences. After an initial learning phase, our agent can execute the optimal policy under any given preference, or automatically infer an underlying preference with very few samples. Experiments across four different domains demonstrate the effectiveness of our approach.},
	urldate = {2025-02-25},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Yang, Runzhe and Sun, Xingyuan and Narasimhan, Karthik},
	year = {2019},
	}

@inproceedings{teoh_generalization_2024,
	title = {On {Generalization} {Within} {Multi}-{Objective} {Reinforcement} {Learning} {Algorithms}},
	url = {https://openreview.net/forum?id=tuEP424UQ5&noteId=ppThlII8GC},
	abstract = {Real-world sequential decision-making tasks often require balancing trade-offs between multiple conflicting objectives, making Multi-Objective Reinforcement Learning (MORL) an increasingly prominent field of research. Despite recent advances, existing MORL literature has narrowly focused on performance within static environments, neglecting the importance of generalizing across diverse settings. Conversely, existing research on generalization in RL has always assumed scalar rewards, overlooking the inherent multi-objectivity of real-world problems. Generalization in the multi-objective context is fundamentally more challenging, as it requires learning a Pareto set of policies addressing varying preferences across multiple objectives. In this paper, we formalize the concept of generalization in MORL and how it can be evaluated. We then contribute a novel benchmark featuring diverse multi-objective domains with parameterized environment configurations to facilitate future studies in this area. Our baseline evaluations of state-of-the-art MORL algorithms on this benchmark reveals limited generalization capabilities, suggesting significant room for improvement. Our empirical findings also expose limitations in the expressivity of scalar rewards, emphasizing the need for multi-objective specifications to achieve effective generalization. We further analyzed the algorithmic complexities within current MORL approaches that could impede the transfer in performance from the single- to multiple-environment settings. This work fills a critical gap and lays the groundwork for future research that brings together two key areas in reinforcement learning: solving multi-objective decision-making problems and generalizing across diverse environments. Code is available at: [https://anonymous.4open.science/r/morl-generalization](https://anonymous.4open.science/r/morl-generalization)},
	language = {en},
	urldate = {2025-02-25},
	author = {Teoh, Jayden and Varakantham, Pradeep and Vamplew, Peter},
	month = oct,
	year = {2024},
	}

@article{acharya_neurosymbolic_2024,
	title = {Neurosymbolic {Reinforcement} {Learning} and {Planning}: {A} {Survey}},
	volume = {5},
	issn = {2691-4581},
	shorttitle = {Neurosymbolic {Reinforcement} {Learning} and {Planning}},
	url = {http://arxiv.org/abs/2309.01038},
	doi = {10.1109/TAI.2023.3311428},
	abstract = {The area of Neurosymbolic Artificial Intelligence (Neurosymbolic AI) is rapidly developing and has become a popular research topic, encompassing sub-fields such as Neurosymbolic Deep Learning (Neurosymbolic DL) and Neurosymbolic Reinforcement Learning (Neurosymbolic RL). Compared to traditional learning methods, Neurosymbolic AI offers significant advantages by simplifying complexity and providing transparency and explainability. Reinforcement Learning(RL), a long-standing Artificial Intelligence(AI) concept that mimics human behavior using rewards and punishment, is a fundamental component of Neurosymbolic RL, a recent integration of the two fields that has yielded promising results. The aim of this paper is to contribute to the emerging field of Neurosymbolic RL by conducting a literature survey. Our evaluation focuses on the three components that constitute Neurosymbolic RL: neural, symbolic, and RL. We categorize works based on the role played by the neural and symbolic parts in RL, into three taxonomies:Learning for Reasoning, Reasoning for Learning and Learning-Reasoning. These categories are further divided into sub-categories based on their applications. Furthermore, we analyze the RL components of each research work, including the state space, action space, policy module, and RL algorithm. Additionally, we identify research opportunities and challenges in various applications within this dynamic field.},
	number = {5},
	urldate = {2025-02-25},
	journal = {IEEE Trans. Artif. Intell.},
	author = {Acharya, K. and Raza, W. and Jr, C. M. J. M. Dourado and Velasquez, A. and Song, H.},
	month = may,
	year = {2024},
	note = {arXiv:2309.01038 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	pages = {1939--1953},
	annote = {Comment: 16 pages, 9 figures, IEEE Transactions on Artificial Intelligence},
	}

@inproceedings{anderson_neurosymbolic_2020,
	title = {Neurosymbolic {Reinforcement} {Learning} with {Formally} {Verified} {Exploration}},
	volume = {33},
	url = {https://proceedings.neurips.cc/paper/2020/hash/448d5eda79895153938a8431919f4c9f-Abstract.html},
	abstract = {We present REVEL, a partially neural reinforcement learning (RL) framework for provably  safe exploration in continuous state and action spaces. A key challenge for provably safe deep RL is that repeatedly verifying neural networks within a learning loop is computationally infeasible. We address this challenge using two policy classes: a general, neurosymbolic class with approximate gradients and a more restricted class of symbolic policies that allows efficient verification. Our learning algorithm is a mirror descent over policies: in each iteration, it safely lifts a symbolic policy into the neurosymbolic space, performs safe gradient updates to the resulting policy, and projects the updated policy into the safe symbolic subset, all without requiring explicit verification of neural networks. Our empirical results show that REVEL enforces safe exploration in many scenarios in which Constrained Policy Optimization does not, and that it can discover policies that outperform those learned through prior approaches to verified exploration.},
	urldate = {2025-02-25},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Anderson, Greg and Verma, Abhinav and Dillig, Isil and Chaudhuri, Swarat},
	year = {2020},
	pages = {6172--6183},
	}

@article{mitchener_detect_2022,
	title = {Detect, {Understand}, {Act}: {A} {Neuro}-symbolic {Hierarchical} {Reinforcement} {Learning} {Framework}},
	volume = {111},
	issn = {1573-0565},
	shorttitle = {Detect, {Understand}, {Act}},
	url = {https://doi.org/10.1007/s10994-022-06142-7},
	doi = {10.1007/s10994-022-06142-7},
	abstract = {In this paper we introduce Detect, Understand, Act (DUA), a neuro-symbolic reinforcement learning framework. The Detect component is composed of a traditional computer vision object detector and tracker. The Act component houses a set of options, high-level actions enacted by pre-trained deep reinforcement learning (DRL) policies. The Understand component provides a novel answer set programming (ASP) paradigm for symbolically implementing a meta-policy over options and effectively learning it using inductive logic programming (ILP). We evaluate our framework on the Animal-AI (AAI) competition testbed, a set of physical cognitive reasoning problems. Given a set of pre-trained DRL policies, DUA requires only a few examples to learn a meta-policy that allows it to improve the state-of-the-art on multiple of the most challenging categories from the testbed. DUA constitutes the first holistic hybrid integration of computer vision, ILP and DRL applied to an AAI-like environment and sets the foundations for further use of ILP in complex DRL challenges.},
	language = {en},
	number = {4},
	urldate = {2025-02-25},
	journal = {Mach Learn},
	author = {Mitchener, Ludovico and Tuckey, David and Crosby, Matthew and Russo, Alessandra},
	month = apr,
	year = {2022},
	keywords = {Artificial Intelligence, Answer set programming, Deep reinforcement learning, Hierarchical reinforcement learning, Inductive logic programming, Neuro-symbolic},
	pages = {1523--1549},
	}

@misc{graf_three_2024,
	title = {Three {Pathways} to {Neurosymbolic} {Reinforcement} {Learning} with {Interpretable} {Model} and {Policy} {Networks}},
	url = {http://arxiv.org/abs/2402.05307},
	doi = {10.48550/arXiv.2402.05307},
	abstract = {Neurosymbolic AI combines the interpretability, parsimony, and explicit reasoning of classical symbolic approaches with the statistical learning of data-driven neural approaches. Models and policies that are simultaneously differentiable and interpretable may be key enablers of this marriage. This paper demonstrates three pathways to implementing such models and policies in a real-world reinforcement learning setting. Specifically, we study a broad class of neural networks that build interpretable semantics directly into their architecture. We reveal and highlight both the potential and the essential difficulties of combining logic, simulation, and learning. One lesson is that learning benefits from continuity and differentiability, but classical logic is discrete and non-differentiable. The relaxation to real-valued, differentiable representations presents a trade-off; the more learnable, the less interpretable. Another lesson is that using logic in the context of a numerical simulation involves a non-trivial mapping from raw (e.g., real-valued time series) simulation data to logical predicates. Some open questions this note exposes include: What are the limits of rule-based controllers, and how learnable are they? Do the differentiable interpretable approaches discussed here scale to large, complex, uncertain systems? Can we truly achieve interpretability? We highlight these and other themes across the three approaches.},
	urldate = {2025-02-25},
	publisher = {arXiv},
	author = {Graf, Peter and Emami, Patrick},
	month = feb,
	year = {2024},
	note = {arXiv:2402.05307 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	}

@inproceedings{liu_constrained_2023,
	title = {Constrained {Decision} {Transformer} for {Offline} {Safe} {Reinforcement} {Learning}},
	issn = {2640-3498},
	url = {https://proceedings.mlr.press/v202/liu23m.html},
	abstract = {Safe reinforcement learning (RL) trains a constraint satisfaction policy by interacting with the environment. We aim to tackle a more challenging problem: learning a safe policy from an offline dataset. We study the offline safe RL problem from a novel multi-objective optimization perspective and propose the ϵϵ{\textbackslash}epsilon-reducible concept to characterize problem difficulties. The inherent trade-offs between safety and task performance inspire us to propose the constrained decision transformer (CDT) approach, which can dynamically adjust the trade-offs during deployment. Extensive experiments show the advantages of the proposed method in learning an adaptive, safe, robust, and high-reward policy. CDT outperforms its variants and strong offline safe RL baselines by a large margin with the same hyperparameters across all tasks, while keeping the zero-shot adaptation capability to different constraint thresholds, making our approach more suitable for real-world RL under constraints.},
	language = {en},
	urldate = {2025-02-25},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Liu, Zuxin and Guo, Zijian and Yao, Yihang and Cen, Zhepeng and Yu, Wenhao and Zhang, Tingnan and Zhao, Ding},
	month = jul,
	year = {2023},
	pages = {21611--21630},
	}

@article{li_deep_2021,
	title = {Deep {Reinforcement} {Learning} for {Multiobjective} {Optimization}},
	volume = {51},
	issn = {2168-2275},
	url = {https://ieeexplore.ieee.org/abstract/document/9040280?casa_token=YwglvZ4zyQ4AAAAA:2IVowxA7eIUnpx6o-MNtog1f98ocL9BjnfoMuiwynvosqK0uLkEZUWAOtq0YocWuWuvkXH_E},
	doi = {10.1109/TCYB.2020.2977661},
	abstract = {This article proposes an end-to-end framework for solving multiobjective optimization problems (MOPs) using deep reinforcement learning (DRL), that we call DRL-based multiobjective optimization algorithm (DRL-MOA). The idea of decomposition is adopted to decompose the MOP into a set of scalar optimization subproblems. Then, each subproblem is modeled as a neural network. Model parameters of all the subproblems are optimized collaboratively according to a neighborhood-based parameter-transfer strategy and the DRL training algorithm. Pareto-optimal solutions can be directly obtained through the trained neural-network models. Specifically, the multiobjective traveling salesman problem (MOTSP) is solved in this article using the DRL-MOA method by modeling the subproblem as a Pointer Network. Extensive experiments have been conducted to study the DRL-MOA and various benchmark methods are compared with it. It is found that once the trained model is available, it can scale to newly encountered problems with no need for retraining the model. The solutions can be directly obtained by a simple forward calculation of the neural network; thereby, no iteration is required and the MOP can be always solved in a reasonable time. The proposed method provides a new way of solving the MOP by means of DRL. It has shown a set of new characteristics, for example, strong generalization ability and fast solving speed in comparison with the existing methods for multiobjective optimizations. The experimental results show the effectiveness and competitiveness of the proposed method in terms of model performance and running time.},
	number = {6},
	urldate = {2025-02-25},
	journal = {IEEE Transactions on Cybernetics},
	author = {Li, Kaiwen and Zhang, Tao and Wang, Rui},
	month = jun,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Cybernetics},
	keywords = {Neural networks, Training, multiobjective optimization, Optimization, Reinforcement learning, Deep reinforcement learning (DRL), Modeling, Pointer Network, traveling salesman problem, Traveling salesman problems, Urban areas},
	pages = {3103--3114},
	}

@inproceedings{fu_multi-objective_2024,
	title = {Multi-objective {Cross}-task {Learning} via {Goal}-conditioned {GPT}-based {Decision} {Transformers} for {Surgical} {Robot} {Task} {Automation}},
	url = {https://ieeexplore.ieee.org/document/10611051},
	doi = {10.1109/ICRA57147.2024.10611051},
	abstract = {Surgical robot task automation has been a promising research topic for improving surgical efficiency and quality. Learning-based methods have been recognized as an interesting paradigm and been increasingly investigated. However, existing approaches encounter difficulties in long-horizon goal-conditioned tasks due to the intricate compositional structure, which requires decision-making for a sequence of sub-steps and understanding of inherent dynamics of goal-reaching tasks. In this paper, we propose a new learning-based framework by leveraging the strong reasoning capability of the GPT-based architecture to automate surgical robotic tasks. The key to our approach is developing a goal-conditioned decision transformer to achieve sequential representations with goal-aware future indicators in order to enhance temporal reasoning. Moreover, considering to exploit a general understanding of dynamics inherent in manipulations, thus making the model’s reasoning ability to be task-agnostic, we also design a cross-task pretraining paradigm that uses multiple training objectives associated with data from diverse tasks. We have conducted extensive experiments on 10 tasks using the surgical robot learning simulator SurRoL [1]. The results show that our new approach achieves promising performance and task versatility compared to existing methods. The learned trajectories can be deployed on the da Vinci Research Kit (dVRK) for validating its practicality in real surgical robot settings. Our project website is at: https://med-air.github.io/SurRoL.},
	urldate = {2025-02-26},
	booktitle = {2024 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Fu, Jiawei and Long, Yonghao and Chen, Kai and Wei, Wang and Dou, Qi},
	month = may,
	year = {2024},
	keywords = {Training, Automation, Cognition, Decision making, Learning systems, Medical robotics, Transformers},
	pages = {13362--13368},
	}

@article{hu_transforming_2024,
	title = {On {Transforming} {Reinforcement} {Learning} {With} {Transformers}: {The} {Development} {Trajectory}},
	volume = {46},
	issn = {1939-3539},
	shorttitle = {On {Transforming} {Reinforcement} {Learning} {With} {Transformers}},
	url = {https://ieeexplore.ieee.org/document/10546317},
	doi = {10.1109/TPAMI.2024.3408271},
	abstract = {Transformers, originally devised for natural language processing (NLP), have also produced significant successes in computer vision (CV). Due to their strong expression power, researchers are investigating ways to deploy transformers for reinforcement learning (RL), and transformer-based models have manifested their potential in representative RL benchmarks. In this paper, we collect and dissect recent advances concerning the transformation of RL with transformers (transformer-based RL (TRL)) to explore the development trajectory and future trends of this field. We group the existing developments into two categories: architecture enhancements and trajectory optimizations, and examine the main applications of TRL in robotic manipulation, text-based games (TBGs), navigation, and autonomous driving. Architecture enhancement methods consider how to apply the powerful transformer structure to RL problems under the traditional RL framework, facilitating more precise modeling of agents and environments compared to traditional deep RL techniques. However, these methods are still limited by the inherent defects of traditional RL algorithms, such as bootstrapping and the “deadly triad”. Trajectory optimization methods treat RL problems as sequence modeling problems and train a joint state-action model over entire trajectories under the behavior cloning framework; such approaches are able to extract policies from static datasets and fully use the long-sequence modeling capabilities of transformers. Given these advancements, the limitations and challenges in TRL are reviewed and proposals regarding future research directions are discussed. We hope that this survey can provide a detailed introduction to TRL and motivate future research in this rapidly developing field.},
	number = {12},
	urldate = {2025-02-26},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Hu, Shengchao and Shen, Li and Zhang, Ya and Chen, Yixin and Tao, Dacheng},
	month = dec,
	year = {2024},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Transformers, Analytical models, Computer architecture, Electronic mail, Literature survey, reinforcement learning, representation learning, Surveys, Task analysis, Trajectory optimization, transformer},
	pages = {8580--8599},
	}

@article{chen_transformer-based_2024,
	title = {Transformer-{Based} {Reinforcement} {Learning} for {Scalable} {Multi}-{UAV} {Area} {Coverage}},
	volume = {25},
	issn = {1558-0016},
	url = {https://ieeexplore.ieee.org/abstract/document/10423879?casa_token=7uq9_5lhlwIAAAAA:dUkfPSlfmXuHPzBO9ZKOGXdw4nQCQ_nrB_9h8Cnetw3Sgf03mj9_Y07g8jYZwKG0Nq7JHg56},
	doi = {10.1109/TITS.2024.3358010},
	abstract = {Compared with terrestrial networks, unmanned aerial vehicles (UAVs) have the characteristics of flexible deployment and strong adaptability, which are an important supplement to intelligent transportation systems (ITS). In this paper, we focus on the multi-UAV network area coverage problem (ACP) which require intelligent UAVs long-term trajectory decisions in the complex and scalable network environment. Multi-agent deep reinforcement learning (DRL) has recently emerged as an effective tool for solving long-term decisions problems. However, since the input dimension of multi-layer perceptron (MLP)-based deep neural network (DNN) is fixed, it is difficult for standard DNN to adapt to a variable number of UAVs and network users. Therefore, we combine Transformer with DRL to meet the scalability of the network and propose a Transformer-based deep multi-agent reinforcement learning (T-MARL) algorithm. Transformer can adapt to variable input dimensions and extract important information from complex network states by attention module. In our research, we find that random initialization of Transformer may cause DRL training failure, so we propose a baseline-assisted pre-training scheme. This scheme can quickly provide an initial policy model for UAVs based on imitation learning, and use the temporal-difference(1) algorithm to initialize policy evaluation network. Finally, based on parameter sharing, T-MARL is applicable to any standard DRL algorithm and supports expansion on networks of different sizes. Experimental results show that T-MARL can make UAVs have cooperative behaviors and perform outstandingly on ACP.},
	number = {8},
	urldate = {2025-02-26},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Chen, Dezhi and Qi, Qi and Fu, Qianlong and Wang, Jingyu and Liao, Jianxin and Han, Zhu},
	month = aug,
	year = {2024},
	note = {Conference Name: IEEE Transactions on Intelligent Transportation Systems},
	keywords = {Training, Reinforcement learning, Transformers, transformer, area coverage, Artificial neural networks, Autonomous aerial vehicles, multi-agent deep reinforcement learning, Scalability, Standards, Unmanned aerial vehicles},
	pages = {10062--10077},
	}

@article{roijers_survey_2013,
	title = {A {Survey} of {Multi}-{Objective} {Sequential} {Decision}-{Making}},
	volume = {48},
	copyright = {Copyright (c)},
	issn = {1076-9757},
	url = {https://www.jair.org/index.php/jair/article/view/10836},
	doi = {10.1613/jair.3987},
	abstract = {Sequential decision-making problems with multiple objectives arise naturally in practice and pose unique challenges for research in decision-theoretic planning and learning, which has largely focused on single-objective settings. This article surveys algorithms designed for sequential decision-making problems with multiple objectives. Though there is a growing body of literature on this subject, little of it makes explicit under what circumstances special methods are needed to solve multi-objective problems. Therefore, we identify three distinct scenarios in which converting such a problem to a single-objective one is impossible, infeasible, or undesirable. Furthermore, we propose a taxonomy that classifies multi-objective methods according to the applicable scenario, the nature of the scalarization function (which projects multi-objective values to scalar ones), and the type of policies considered. We show how these factors determine the nature of an optimal solution, which can be a single policy, a convex hull, or a Pareto front. Using this taxonomy, we survey the literature on multi-objective methods for planning and learning. Finally, we discuss key applications of such methods and outline opportunities for future work.},
	language = {en},
	urldate = {2025-03-26},
	journal = {Journal of Artificial Intelligence Research},
	author = {Roijers, D. M. and Vamplew, P. and Whiteson, S. and Dazeley, R.},
	month = oct,
	year = {2013},
	pages = {67--113},
	}

@article{mao_disassembly_2021,
	title = {Disassembly sequence planning of waste auto parts},
	volume = {71},
	issn = {1096-2247},
	url = {https://doi.org/10.1080/10962247.2020.1871444},
	doi = {10.1080/10962247.2020.1871444},
	abstract = {The disassembly of used products is a critical procedure in remanufacturing, and different disassembly strategies are often obtained from different perspectives. To describe the disassembly process more accurately, the uncertainty of the information in the disassembly process should be considered. Therefore, random variables are introduced for disassembly time, cost, and effort. Based on the extended stochastic Petri net modeling method and stochastic programming theory, a stochastic optimization algorithm combined with artificial intelligence technology and a multiobjective genetic algorithm are designed, and a multiobjective optimization model for the disassembly sequence of used car parts under uncertain conditions is successfully constructed. This model considers the viewpoint of the decision maker. Moreover, the Monte Carlo method is applied to solve the multiobjective optimization model, and the validity and practicability of the model are verified by an example of an automotive transmission. Implications: With the rapid development of the economy and the shortening of the product life cycle, the rate of product renewal is getting faster and faster, which also leads to the production of a large number of waste products. According to the forecast of the relevant departments, it is estimated that, in 2020, there will be about 35 million used televisions, 15 million used refrigerators, 13 million used washing machines, 12 million used air conditioners, 57 million used computers, and 8.3 million scrapped cars. Waste products contain a lot of renewable resources. If they cannot be effectively recycled, it will be a great waste of resources, and unreasonable disposal of waste products may have a negative impact on the environment. Therefore, due to environmental pressure and economic drive, product recycling and remanufacturing activities have caused widespread concern in society. Disassembly is defined as the operation or activity of disassembling an assembly such as a product, assembly, or component, and is the result of multiple removal operations of the product. It is a prerequisite for the efficient recycling of products and the first link in remanufacturing, that is, disassembly as a new production activity, which can provide raw materials for the smooth progress of the remanufacturing production plan, namely, old rough or used parts. Efficient dismantling not only saves natural resources and energy, but also effectively reduces environmental pollution. It is also an important guarantee for promoting the healthy development of the circular economy and achieving sustainable industrial development. The length of time required for the dismantling process, the level of costs, and the amount of profits obtained will directly affect the economic benefits of the recycling of end-of-life products. Therefore, the evaluation and optimization of the dismantling process of waste products have become one of the current hot issues. The research on the dismantling of waste products is conducive to speeding up the recycling process of waste, to a greater extent, the rapid and full recovery of resources, and to a certain extent, it will provide value basis and theoretical significance for subsequent research.},
	number = {5},
	urldate = {2025-06-05},
	journal = {Journal of the Air \& Waste Management Association},
	publisher = {Taylor \& Francis},
	author = {Mao, Jia and , Dou, Hong and , Zhe, Chen and , Ma, Changhai and , Li, Weiwen and and Wang, Ju},
	month = may,
	year = {2021},
	note = {\_eprint: https://doi.org/10.1080/10962247.2020.1871444},
	pages = {607--619},
	}

@misc{mao_position_2024,
	title = {Position: {Graph} {Foundation} {Models} are {Already} {Here}},
	shorttitle = {Position},
	url = {http://arxiv.org/abs/2402.02216},
	doi = {10.48550/arXiv.2402.02216},
	abstract = {Graph Foundation Models (GFMs) are emerging as a significant research topic in the graph domain, aiming to develop graph models trained on extensive and diverse data to enhance their applicability across various tasks and domains. Developing GFMs presents unique challenges over traditional Graph Neural Networks (GNNs), which are typically trained from scratch for specific tasks on particular datasets. The primary challenge in constructing GFMs lies in effectively leveraging vast and diverse graph data to achieve positive transfer. Drawing inspiration from existing foundation models in the CV and NLP domains, we propose a novel perspective for the GFM development by advocating for a ``graph vocabulary'', in which the basic transferable units underlying graphs encode the invariance on graphs. We ground the graph vocabulary construction from essential aspects including network analysis, expressiveness, and stability. Such a vocabulary perspective can potentially advance the future GFM design in line with the neural scaling laws. All relevant resources with GFM design can be found here.},
	urldate = {2025-06-11},
	publisher = {arXiv},
	author = {Mao, Haitao and Chen, Zhikai and Tang, Wenzhuo and Zhao, Jianan and Ma, Yao and Zhao, Tong and Shah, Neil and Galkin, Mikhail and Tang, Jiliang},
	month = may,
	year = {2024},
	note = {arXiv:2402.02216 [cs]},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: 23 pages, 2 figures},
	}

@misc{lo_end--end_2024,
	title = {End-to-{End} {Ontology} {Learning} with {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2410.23584},
	doi = {10.48550/arXiv.2410.23584},
	abstract = {Ontologies are useful for automatic machine processing of domain knowledge as they represent it in a structured format. Yet, constructing ontologies requires substantial manual effort. To automate part of this process, large language models (LLMs) have been applied to solve various subtasks of ontology learning. However, this partial ontology learning does not capture the interactions between subtasks. We address this gap by introducing OLLM, a general and scalable method for building the taxonomic backbone of an ontology from scratch. Rather than focusing on subtasks, like individual relations between entities, we model entire subcomponents of the target ontology by finetuning an LLM with a custom regulariser that reduces overfitting on high-frequency concepts. We introduce a novel suite of metrics for evaluating the quality of the generated ontology by measuring its semantic and structural similarity to the ground truth. In contrast to standard metrics, our metrics use deep learning techniques to define more robust distance measures between graphs. Both our quantitative and qualitative results on Wikipedia show that OLLM outperforms subtask composition methods, producing more semantically accurate ontologies while maintaining structural integrity. We further demonstrate that our model can be effectively adapted to new domains, like arXiv, needing only a small number of training examples. Our source code and datasets are available at https://github.com/andylolu2/ollm.},
	urldate = {2025-07-03},
	publisher = {arXiv},
	author = {Lo, Andy and Jiang, Albert Q. and Li, Wenda and Jamnik, Mateja},
	month = oct,
	year = {2024},
	note = {arXiv:2410.23584 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	}

@misc{baldazzi_fine-tuning_2023,
	title = {Fine-tuning {Large} {Enterprise} {Language} {Models} via {Ontological} {Reasoning}},
	url = {http://arxiv.org/abs/2306.10723},
	doi = {10.48550/arXiv.2306.10723},
	abstract = {Large Language Models (LLMs) exploit fine-tuning as a technique to adapt to diverse goals, thanks to task-specific training data. Task specificity should go hand in hand with domain orientation, that is, the specialization of an LLM to accurately address the tasks of a given realm of interest. However, models are usually fine-tuned over publicly available data or, at most, over ground data from databases, ignoring business-level definitions and domain experience. On the other hand, Enterprise Knowledge Graphs (EKGs) are able to capture and augment such domain knowledge via ontological reasoning. With the goal of combining LLM flexibility with the domain orientation of EKGs, we propose a novel neurosymbolic architecture that leverages the power of ontological reasoning to build task- and domain-specific corpora for LLM fine-tuning.},
	urldate = {2025-07-03},
	publisher = {arXiv},
	author = {Baldazzi, Teodoro and Bellomarini, Luigi and Ceri, Stefano and Colombo, Andrea and Gentili, Andrea and Sallinger, Emanuel},
	month = sep,
	year = {2023},
	note = {arXiv:2306.10723 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Databases, Computer Science - Logic in Computer Science},
	annote = {Comment: Accepted at RuleML 2023},
	}

@misc{mai_llms_2024,
	title = {Do {LLMs} {Really} {Adapt} to {Domains}? {An} {Ontology} {Learning} {Perspective}},
	shorttitle = {Do {LLMs} {Really} {Adapt} to {Domains}?},
	url = {http://arxiv.org/abs/2407.19998},
	doi = {10.48550/arXiv.2407.19998},
	abstract = {Large Language Models (LLMs) have demonstrated unprecedented prowess across various natural language processing tasks in various application domains. Recent studies show that LLMs can be leveraged to perform lexical semantic tasks, such as Knowledge Base Completion (KBC) or Ontology Learning (OL). However, it has not effectively been verified whether their success is due to their ability to reason over unstructured or semi-structured data, or their effective learning of linguistic patterns and senses alone. This unresolved question is particularly crucial when dealing with domain-specific data, where the lexical senses and their meaning can completely differ from what a LLM has learned during its training stage. This paper investigates the following question: Do LLMs really adapt to domains and remain consistent in the extraction of structured knowledge, or do they only learn lexical senses instead of reasoning? To answer this question and, we devise a controlled experiment setup that uses WordNet to synthesize parallel corpora, with English and gibberish terms. We examine the differences in the outputs of LLMs for each corpus in two OL tasks: relation extraction and taxonomy discovery. Empirical results show that, while adapting to the gibberish corpora, off-the-shelf LLMs do not consistently reason over semantic relationships between concepts, and instead leverage senses and their frame. However, fine-tuning improves the performance of LLMs on lexical semantic tasks even when the domain-specific terms are arbitrary and unseen during pre-training, hinting at the applicability of pre-trained LLMs for OL.},
	urldate = {2025-07-30},
	publisher = {arXiv},
	author = {Mai, Huu Tan and Chu, Cuong Xuan and Paulheim, Heiko},
	month = jul,
	year = {2024},
	note = {arXiv:2407.19998 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	annote = {Comment: Accepted at ISWC 2024},
	}

@article{nawaz_review_2025,
	title = {A review of neuro-symbolic {AI} integrating reasoning and learning for advanced cognitive systems},
	volume = {26},
	issn = {2667-3053},
	url = {https://www.sciencedirect.com/science/article/pii/S2667305325000675},
	doi = {10.1016/j.iswa.2025.200541},
	abstract = {Neuro-symbolic AI represents the convergence of two principal paradigms in artificial intelligence: neural networks, which are efficient in data-driven learning, and symbolic reasoning, which offers explainability and logical inference. This hybrid methodology combines the adaptability of neural networks with symbolic AI's interpretability and formal reasoning abilities, which provide a practical framework for advanced cognitive systems. This paper analyzes the present condition of neuro-symbolic AI, emphasizing essential techniques that combine reasoning and learning. We explore models such as Logic Tensor Networks, Differentiable Logic Programs, and Neural Theorem Provers. The study analyzes their impact on the advancement of cognitive systems in natural language processing, robotics, and decision-making. The paper examines the challenges faced by neuro-symbolic AI, such as scalability, integration with multimodal data, and maintaining interpretability without compromising efficiency. By evaluating the strengths and weaknesses of many methodologies, we comprehensively understand the field's development and its potential to revolutionize intelligent systems. In addition, we identify emerging research areas, including the incorporation of ethical frameworks and the development of adaptive dynamic neuro-symbolic systems that respond in real-time. This review aims to guide future research by providing insights into the potential of neuro-symbolic AI to influence the development of the next generation of intelligent, explainable, and adaptive systems.},
	urldate = {2025-08-19},
	journal = {Intelligent Systems with Applications},
	author = {Nawaz, Uzma and Anees-ur-Rahaman, Mufti and Saeed, Zubair},
	month = jun,
	year = {2025},
	pages = {200541},
	}

@incollection{besold_chapter_2021,
	title = {Chapter 1. {Neural}-{Symbolic} {Learning} and {Reasoning}: {A} {Survey} and {Interpretation}\&lt;span ref-type=\&quot;fn\&quot; rid=\&quot;{FAIA210348}\_fn001\&quot; style=\&quot;display:none\&quot;\&gt; \&lt;sup\&gt;1\&lt;/sup\&gt; \&lt;/span\&gt;},
	shorttitle = {Chapter 1. {Neural}-{Symbolic} {Learning} and {Reasoning}},
	url = {https://ebooks.iospress.nl/doi/10.3233/FAIA210348},
	doi = {10.3233/FAIA210348},
	language = {en},
	urldate = {2025-08-20},
	booktitle = {Neuro-{Symbolic} {Artificial} {Intelligence}: {The} {State} of the {Art}},
	publisher = {IOS Press},
	author = {Besold, Tarek R. and d’Avila Garcez, Artur and Bader, Sebastian and Bowman, Howard and Domingos, Pedro and Hitzler, Pascal and K\&\#252 and Hnberger, Kai-Uwe and Lamb, Luis C. and Lima, Priscila Machado Vieira and de Penning, Leo and Pinkas, Gadi and Poon, Hoifung and Zaverucha, Gerson},
	year = {2021},
	pages = {1--51},
	}

@article{bhuyan_neuro-symbolic_2024,
	title = {Neuro-symbolic artificial intelligence: a survey},
	volume = {36},
	issn = {1433-3058},
	shorttitle = {Neuro-symbolic artificial intelligence},
	url = {https://doi.org/10.1007/s00521-024-09960-z},
	doi = {10.1007/s00521-024-09960-z},
	abstract = {The goal of the growing discipline of neuro-symbolic artificial intelligence (AI) is to develop AI systems with more human-like reasoning capabilities by combining symbolic reasoning with connectionist learning. We survey the literature on neuro-symbolic AI during the last two decades, including books, monographs, review papers, contribution pieces, opinion articles, foundational workshops/talks, and related PhD theses. Four main features of neuro-symbolic AI are discussed, including representation, learning, reasoning, and decision-making. Finally, we discuss the many applications of neuro-symbolic AI, including question answering, robotics, computer vision, healthcare, and more. Scalability, explainability, and ethical considerations are also covered, as well as other difficulties and limits of neuro-symbolic AI. This study summarizes the current state of the art in neuro-symbolic artificial intelligence.},
	language = {en},
	number = {21},
	urldate = {2025-08-20},
	journal = {Neural Comput \& Applic},
	author = {Bhuyan, Bikram Pratim and Ramdane-Cherif, Amar and Tomar, Ravi and Singh, T. P.},
	month = jul,
	year = {2024},
	keywords = {Neural networks, Artificial intelligence, Knowledge representation and reasoning, Machine learning, Neuro-symbolic artificial intelligence, Spatial-temporal data},
	pages = {12809--12844},
	}

@article{lu_surveying_2024,
	title = {Surveying neuro-symbolic approaches for reliable artificial intelligence of things},
	volume = {10},
	issn = {2199-4676},
	url = {https://doi.org/10.1007/s40860-024-00231-1},
	doi = {10.1007/s40860-024-00231-1},
	abstract = {The integration of Artificial Intelligence (AI) with the Internet of Things (IoT), known as the Artificial Intelligence of Things (AIoT), enhances the devices’ processing and analysis capabilities and disrupts such sectors as healthcare, industry, and oil. However, AIoT’s complexity and scale are challenging for traditional machine learning (ML). Deep learning offers a solution but has limited testability, verifiability, and interpretability. In turn, the neuro-symbolic paradigm addresses these challenges by combining the robustness of symbolic AI with the flexibility of DL, enabling AI systems to reason, make decisions, and generalize knowledge from large datasets better. This paper reviews state-of-the-art DL models for IoT, identifies their limitations, and explores how neuro-symbolic methods can overcome them. It also discusses key challenges and research opportunities in enhancing AIoT reliability with neuro-symbolic approaches, including hard-coded symbolic AI, multimodal sensor data, biased interpretability, trading-off interpretability, and performance, complexity in integrating neural networks and symbolic AI, and ethical and societal challenges.},
	language = {en},
	number = {3},
	urldate = {2025-08-20},
	journal = {J Reliable Intell Environ},
	author = {Lu, Zhen and Afridi, Imran and Kang, Hong Jin and Ruchkin, Ivan and Zheng, Xi},
	month = sep,
	year = {2024},
	keywords = {Neuro-symbolic, AIoT, Interpretability, Testability, Verifiability},
	pages = {257--279},
	}

@article{wang_voyager_2023,
	title = {Voyager: {An} {Open}-{Ended} {Embodied} {Agent} with {Large} {Language} {Models}},
	issn = {2835-8856},
	shorttitle = {Voyager},
	url = {https://openreview.net/forum?id=ehfRiF0R3a},
	abstract = {We introduce Voyager, the first LLM-powered embodied lifelong learning agent in an open-ended world that continuously explores, acquires diverse skills, and makes novel discoveries without human intervention in Minecraft. Voyager consists of three key components: 1) an automatic curriculum that maximizes exploration, 2) an ever-growing skill library of executable code for storing and retrieving complex behaviors, and 3) a new iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification for program improvement. Voyager interacts with GPT-4 via blackbox queries, which bypasses the need for model parameter fine-tuning. The skills developed by Voyager are temporally extended, interpretable, and compositional, which compounds the agent’s capability rapidly and alleviates catastrophic forgetting. Empirically, Voyager demonstrates strong in-context lifelong learning capabilities. It outperforms prior SOTA by obtaining 3.1x more unique items, unlocking tech tree milestones up to 15.3x faster, and traveling 2.3x longer distances. Voyager is able to utilize the learned skill library in a new Minecraft world to solve novel tasks from scratch, while other techniques struggle to generalize.},
	language = {en},
	urldate = {2025-08-20},
	journal = {Transactions on Machine Learning Research},
	author = {Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
	month = nov,
	year = {2023},
	}

@inproceedings{xu_prediction-guided_2020,
	title = {Prediction-{Guided} {Multi}-{Objective} {Reinforcement} {Learning} for {Continuous} {Robot} {Control}},
	issn = {2640-3498},
	url = {https://proceedings.mlr.press/v119/xu20h.html},
	abstract = {Many real-world control problems involve conflicting objectives where we desire a dense and high-quality set of control policies that are optimal for different objective preferences (called Pareto-optimal). While extensive research in multi-objective reinforcement learning (MORL) has been conducted to tackle such problems, multi-objective optimization for complex continuous robot control is still under-explored. In this work, we propose an efficient evolutionary learning algorithm to find the Pareto set approximation for continuous robot control problems, by extending a state-of-the-art RL algorithm and presenting a novel prediction model to guide the learning process. In addition to efficiently discovering the individual policies on the Pareto front, we construct a continuous set of Pareto-optimal solutions by Pareto analysis and interpolation. Furthermore, we design seven multi-objective RL environments with continuous action space, which is the first benchmark platform to evaluate MORL algorithms on various robot control problems. We test the previous methods on the proposed benchmark problems, and the experiments show that our approach is able to find a much denser and higher-quality set of Pareto policies than the existing algorithms.},
	language = {en},
	urldate = {2025-08-20},
	booktitle = {Proceedings of the 37th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Xu, Jie and Tian, Yunsheng and Ma, Pingchuan and Rus, Daniela and Sueda, Shinjiro and Matusik, Wojciech},
	month = nov,
	year = {2020},
	pages = {10607--10616},
	}

@article{manhaeve_neural_2021,
	title = {Neural probabilistic logic programming in {DeepProbLog}},
	volume = {298},
	issn = {0004-3702},
	url = {https://www.sciencedirect.com/science/article/pii/S0004370221000552},
	doi = {10.1016/j.artint.2021.103504},
	abstract = {We introduce DeepProbLog, a neural probabilistic logic programming language that incorporates deep learning by means of neural predicates. We show how existing inference and learning techniques of the underlying probabilistic logic programming language ProbLog can be adapted for the new language. We theoretically and experimentally demonstrate that DeepProbLog supports (i) both symbolic and subsymbolic representations and inference, (ii) program induction, (iii) probabilistic (logic) programming, and (iv) (deep) learning from examples. To the best of our knowledge, this work is the first to propose a framework where general-purpose neural networks and expressive probabilistic-logical modeling and reasoning are integrated in a way that exploits the full expressiveness and strengths of both worlds and can be trained end-to-end based on examples.},
	urldate = {2025-08-20},
	journal = {Artificial Intelligence},
	author = {Manhaeve, Robin and Dumančić, Sebastijan and Kimmig, Angelika and Demeester, Thomas and De Raedt, Luc},
	month = sep,
	year = {2021},
	keywords = {Neural networks, Learning and reasoning, Logic, Neuro-symbolic integration, Probabilistic logic programming, Probability},
	pages = {103504},
	}

@book{davila_garcez_neural-symbolic_2002,
	address = {London},
	series = {Perspectives in {Neural} {Computing}},
	title = {Neural-{Symbolic} {Learning} {Systems}},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-1-85233-512-0 978-1-4471-0211-3},
	url = {http://link.springer.com/10.1007/978-1-4471-0211-3},
	doi = {10.1007/978-1-4471-0211-3},
	urldate = {2025-08-20},
	publisher = {Springer},
	author = {d’Avila Garcez, Artur S. and Broda, Krysia B. and Gabbay, Dov M.},
	editor = {Taylor, J. G.},
	year = {2002},
	keywords = {Artificial neural networks, Machine learning, artificial intelligence, Hybrid systems, intelligence, intelligent systems, knowledge representation, learning, logic, logic programming, Neural-symbolic integration, nonmonotonic reasoning},
	}

@article{garcez_neurosymbolic_2023,
	title = {Neurosymbolic {AI}: the 3rd wave},
	volume = {56},
	issn = {1573-7462},
	shorttitle = {Neurosymbolic {AI}},
	url = {https://doi.org/10.1007/s10462-023-10448-w},
	doi = {10.1007/s10462-023-10448-w},
	abstract = {Current advances in Artificial Intelligence (AI) and Machine Learning have achieved unprecedented impact across research communities and industry. Nevertheless, concerns around trust, safety, interpretability and accountability of AI were raised by influential thinkers. Many identified the need for well-founded knowledge representation and reasoning to be integrated with deep learning and for sound explainability. Neurosymbolic computing has been an active area of research for many years seeking to bring together robust learning in neural networks with reasoning and explainability by offering symbolic representations for neural models. In this paper, we relate recent and early research in neurosymbolic AI with the objective of identifying the most important ingredients of neurosymbolic AI systems. We focus on research that integrates in a principled way neural network-based learning with symbolic knowledge representation and logical reasoning. Finally, this review identifies promising directions and challenges for the next decade of AI research from the perspective of neurosymbolic computing, commonsense reasoning and causal explanation.},
	language = {en},
	number = {11},
	urldate = {2025-08-20},
	journal = {Artif Intell Rev},
	author = {Garcez, Artur d’Avila and Lamb, Luís C.},
	month = nov,
	year = {2023},
	keywords = {Deep learning, Machine learning, Cognitive reasoning, Explainable AI, Neurosymbolic AI, Reasoning, Trustworthy AI},
	pages = {12387--12406},
	}

@misc{colelough_neuro-symbolic_2025,
	title = {Neuro-{Symbolic} {AI} in 2024: {A} {Systematic} {Review}},
	shorttitle = {Neuro-{Symbolic} {AI} in 2024},
	url = {http://arxiv.org/abs/2501.05435},
	doi = {10.48550/arXiv.2501.05435},
	abstract = {Background: The field of Artificial Intelligence has undergone cyclical periods of growth and decline, known as AI summers and winters. Currently, we are in the third AI summer, characterized by significant advancements and commercialization, particularly in the integration of Symbolic AI and Sub-Symbolic AI, leading to the emergence of Neuro-Symbolic AI. Methods: The review followed the PRISMA methodology, utilizing databases such as IEEE Explore, Google Scholar, arXiv, ACM, and SpringerLink. The inclusion criteria targeted peer-reviewed papers published between 2020 and 2024. Papers were screened for relevance to Neuro-Symbolic AI, with further inclusion based on the availability of associated codebases to ensure reproducibility. Results: From an initial pool of 1,428 papers, 167 met the inclusion criteria and were analyzed in detail. The majority of research efforts are concentrated in the areas of learning and inference (63\%), logic and reasoning (35\%), and knowledge representation (44\%). Explainability and trustworthiness are less represented (28\%), with Meta-Cognition being the least explored area (5\%). The review identifies significant interdisciplinary opportunities, particularly in integrating explainability and trustworthiness with other research areas. Conclusion: Neuro-Symbolic AI research has seen rapid growth since 2020, with concentrated efforts in learning and inference. Significant gaps remain in explainability, trustworthiness, and Meta-Cognition. Addressing these gaps through interdisciplinary research will be crucial for advancing the field towards more intelligent, reliable, and context-aware AI systems.},
	urldate = {2025-09-12},
	publisher = {arXiv},
	author = {Colelough, Brandon C. and Regli, William},
	month = apr,
	year = {2025},
	note = {arXiv:2501.05435 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	annote = {Comment: 19 pages},
	}

@article{kautz_third_2022,
	title = {The {Third} {AI} {Summer}: {AAAI} {Robert} {S}. {Engelmore} {Memorial} {Lecture}},
	volume = {43},
	copyright = {Copyright (c) 2022 AI Magazine},
	issn = {2371-9621},
	shorttitle = {The {Third} {AI} {Summer}},
	url = {https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/19122},
	doi = {10.1002/aaai.12036},
	abstract = {This article summarizes the author's Robert S. Englemore Memorial Lecture presented at the Thirty-Fourth AAAI Conference on Artificial Intelligence on February 10, 2020. It explores recurring themes in the history of AI, real and imagined dangers from AI, and the future of the field.},
	language = {en},
	number = {1},
	urldate = {2025-09-12},
	journal = {AI Magazine},
	author = {Kautz, Henry},
	month = mar,
	year = {2022},
	pages = {105--125},
	}

@article{yu_survey_2023,
	title = {A survey on neural-symbolic learning systems},
	volume = {166},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608023003398},
	doi = {10.1016/j.neunet.2023.06.028},
	abstract = {In recent years, neural systems have demonstrated highly effective learning ability and superior perception intelligence. However, they have been found to lack effective reasoning and cognitive ability. On the other hand, symbolic systems exhibit exceptional cognitive intelligence but suffer from poor learning capabilities when compared to neural systems. Recognizing the advantages and disadvantages of both methodologies, an ideal solution emerges: combining neural systems and symbolic systems to create neural-symbolic learning systems that possess powerful perception and cognition. The purpose of this paper is to survey the advancements in neural-symbolic learning systems from four distinct perspectives: challenges, methods, applications, and future directions. By doing so, this research aims to propel this emerging field forward, offering researchers a comprehensive and holistic overview. This overview will not only highlight the current state-of-the-art but also identify promising avenues for future research.},
	urldate = {2025-09-12},
	journal = {Neural Networks},
	author = {Yu, Dongran and Yang, Bo and Liu, Dayou and Wang, Hui and Pan, Shirui},
	month = sep,
	year = {2023},
	keywords = {Neural networks, Logic, Knowledge graphs, Neural-symbolic learning systems, Symbolic reasoning, Symbols},
	pages = {105--126},
	}

@article{hsiao_neural_2002,
	title = {A neural network based approach for product form design},
	volume = {23},
	issn = {0142-694X},
	url = {https://www.sciencedirect.com/science/article/pii/S0142694X01000151},
	doi = {10.1016/S0142-694X(01)00015-1},
	abstract = {A neural network based approach for product design is addressed in this article. Computer modeling, fuzzy set theory and semantic difference method are applied to set up an experiment. The experimental results are analyzed by applied back-propagation neural network, which establish the relationships between product–form parameters and adjective image words. A database for the connections among the design elements, product images and shape generation rules was constructed. A computer-aided system for product–form design was then developed based on this database. With the aid of this design system, a designer can generate 3D models of any product with different images by providing basic design elements and shape generation rules. Simultaneously, a rendered 3D model of the designed product and its images are also presented by this system. Therefore, changing the configuration parameter(s) until the product shape is acceptable can modify the image of a product. In this manner, the designed product can fit more closely to the consumers' desire. Chair design is taken as a case study; but this method can be used to develop other products.},
	number = {1},
	urldate = {2025-09-12},
	journal = {Design Studies},
	author = {Hsiao, Shih-Wen and Huang, H. C},
	month = jan,
	year = {2002},
	keywords = {computer-aided design, industrial design, neural network, perception, product design},
	pages = {67--84},
	}

@article{huang_artificial_1994,
	title = {Artificial neural networks in manufacturing: {Concepts}, applications, and perspectives},
	volume = {17},
	shorttitle = {Artificial neural networks in manufacturing},
	doi = {10.1109/95.296402},
	abstract = {New approaches and techniques are continuously and rapidly
introduced and adopted in today's manufacturing environment. Recently, there has been an explosion of interest in applying artificial neural networks to manufacturing. Artificial neural networks have several advantages that are desired in manufacturing practice, including
learning and adapting ability, parallel distributed computation,
robustness, etc. There is an expectation that neural network techniques can lead to the realization of truly intelligent manufacturing systems. This paper introduces the basic concepts of neural networks and reviews the current application of neural networks in manufacturing. The
problems with neural networks are also identified and some possible solutions are suggested. The aim of the authors is to provide useful guidelines and references for the research and implementation of
artificial neural networks in the field of manufacturing},
	journal = {Components, Packaging, and Manufacturing Technology, Part A, IEEE Transactions on},
	author = {Huang, Samuel and Zhang, Hong-Chao},
	month = jul,
	year = {1994},
	pages = {212--228},
	}

@article{xie_graph_2022,
	title = {Graph neural network-enabled manufacturing method classification from engineering drawings},
	volume = {142},
	issn = {0166-3615},
	url = {https://www.sciencedirect.com/science/article/pii/S016636152200094X},
	doi = {10.1016/j.compind.2022.103697},
	abstract = {While millions of scanned engineering drawings are received every year, the online quotation companies for custom mechanical parts have experienced a surging need to increase their processing efficiency by replacing the currently manual inspection process with an automatic system. Previous work has used traditional, and data-driven computer-vision approaches to detect symbols and text information from the drawings. However, there lacks a unified framework to determine the associated manufacturing processes as a critical step for realizing an automatic quoting system. In this paper, we propose a computational framework to automatically determine the manufacturing method appropriate to produce each queried engineering drawing, such as lathing, sheet metal bending, and milling. We present a data-driven framework that directly processes the raster images with a series of pre-processing steps and accurately determines the corresponding manufacturing methods for the queried part with a graph neural network. We propose a novel line tracing algorithm to transform complex geometries in engineering drawings into vectorized line segments with minimal information loss. To extract the shape contours, we use an efficient image segmentation network to remove the information tables, followed by a sequential graph neural network to detect and eliminate dimension lines. Finally, we propose a novel graph neural network with updated graph connections to hierarchically distill graph descriptors and classify the engineering drawing by its appropriate manufacturing method. Our framework has been validated on industry datasets. We verify that our framework can effectively classify the engineering drawings with an accuracy of 90.78\%. We further assess our framework by comparing it against state-of-the-art image classification algorithms(+17.20\%).},
	urldate = {2025-09-12},
	journal = {Computers in Industry},
	author = {Xie, Liuyue and Lu, Yao and Furuhata, Tomotake and Yamakawa, Soji and Zhang, Wentai and Regmi, Amit and Kara, Levent and Shimada, Kenji},
	month = nov,
	year = {2022},
	keywords = {Engineering drawing, Graph neural network, Hierarchical graph learning, Image classification, Manufacturing method, Vectorization},
	pages = {103697},
	}

@article{terziyan_taxonomy-informed_2024,
	series = {5th {International} {Conference} on {Industry} 4.0 and {Smart} {Manufacturing} ({ISM} 2023)},
	title = {Taxonomy-{Informed} {Neural} {Networks} for {Smart} {Manufacturing}},
	volume = {232},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050924001376},
	doi = {10.1016/j.procs.2024.01.137},
	abstract = {A neural network (NN) is known to be an efficient and learnable tool supporting decision-making processes particularly in Industry 4.0. The majority of NNs are data-driven and, therefore, depend on training data quantity and quality. The current trend in enhancing data-driven models with knowledge-based models promises to enable effective NNs with less data. So-called physics-informed NNs use additional knowledge from computational science to improve NN training. Quite much of the knowledge is available as logical constraints from domain ontologies, and NNs may benefit from using it. In this paper, we study the concept of Taxonomy-Informed NN (TINN), which combines data-driven training of NNs with ontological knowledge. We study different patterns of NN training with additional knowledge on class-subclass hierarchies and instance-class relationships with potential for federated learning. Our experiments show that additional knowledge, which influences TINNs’ training process through the loss function at backpropagation, improves the quality of trained models.},
	urldate = {2025-09-12},
	journal = {Procedia Computer Science},
	author = {Terziyan, Vagan and Vitko, Oleksandra},
	month = jan,
	year = {2024},
	keywords = {Industry 4.0, informed machine learning, machine learning, neural networks, physics-informed neural networks, taxonomy},
	pages = {1388--1399},
	}

@article{peres_industrial_2020,
	title = {Industrial {Artificial} {Intelligence} in {Industry} 4.0 - {Systematic} {Review}, {Challenges} and {Outlook}},
	volume = {8},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/abstract/document/9285283},
	doi = {10.1109/ACCESS.2020.3042874},
	abstract = {The advent of the Industry 4.0 initiative has made it so that manufacturing environments are becoming more and more dynamic, connected but also inherently more complex, with additional inter-dependencies, uncertainties and large volumes of data being generated. Recent advances in Industrial Artificial Intelligence have showcased the potential of this technology to assist manufacturers in tackling the challenges associated with this digital transformation of Cyber-Physical Systems, through its data-driven predictive analytics and capacity to assist decision-making in highly complex, non-linear and often multistage environments. However, the industrial adoption of such solutions is still relatively low beyond the experimental pilot stage, as real environments provide unique and difficult challenges for which organizations are still unprepared. The aim of this paper is thus two-fold. First, a systematic review of current Industrial Artificial Intelligence literature is presented, focusing on its application in real manufacturing environments to identify the main enabling technologies and core design principles. Then, a set of key challenges and opportunities to be addressed by future research efforts are formulated along with a conceptual framework to bridge the gap between research in this field and the manufacturing industry, with the goal of promoting industrial adoption through a successful transition towards a digitized and data-driven company-wide culture. This paper is among the first to provide a clear definition and holistic view of Industrial Artificial Intelligence in the Industry 4.0 landscape, identifying and analysing its fundamental building blocks and ongoing trends. Its findings are expected to assist and empower researchers and manufacturers alike to better understand the requirements and steps necessary for a successful transition into Industry 4.0 supported by AI, as well as the challenges that may arise during this process.},
	urldate = {2025-09-12},
	journal = {IEEE Access},
	author = {Peres, Ricardo Silva and Jia, Xiaodong and Lee, Jay and Sun, Keyi and Colombo, Armando Walter and Barata, Jose},
	year = {2020},
	keywords = {Systematics, Decision making, Artificial intelligence, Industry 4.0, digital transformation, framework, guidelines, Industries, manufacturing, Manufacturing, Robots, Service robots, systematic review},
	pages = {220121--220139},
}

@misc{dellermann_future_2021,
	title = {The future of human-{AI} collaboration: a taxonomy of design knowledge for hybrid intelligence systems},
	shorttitle = {The future of human-{AI} collaboration},
	url = {http://arxiv.org/abs/2105.03354},
	doi = {10.48550/arXiv.2105.03354},
	abstract = {Recent technological advances, especially in the field of machine learning, provide astonishing progress on the road towards artificial general intelligence. However, tasks in current real-world business applications cannot yet be solved by machines alone. We, therefore, identify the need for developing socio-technological ensembles of humans and machines. Such systems possess the ability to accomplish complex goals by combining human and artificial intelligence to collectively achieve superior results and continuously improve by learning from each other. Thus, the need for structured design knowledge for those systems arises. Following a taxonomy development method, this article provides three main contributions: First, we present a structured overview of interdisciplinary research on the role of humans in the machine learning pipeline. Second, we envision hybrid intelligence systems and conceptualize the relevant dimensions for system design for the first time. Finally, we offer useful guidance for system developers during the implementation of such applications.},
	urldate = {2025-09-12},
	publisher = {arXiv},
	author = {Dellermann, Dominik and Calma, Adrian and Lipusch, Nikolaus and Weber, Thorsten and Weigel, Sascha and Ebel, Philipp},
	month = may,
	year = {2021},
	note = {arXiv:2105.03354 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction},
}

@misc{felten_multi-objective_2024,
	title = {Multi-{Objective} {Reinforcement} {Learning} {Based} on {Decomposition}: {A} {Taxonomy} and {Framework}},
	shorttitle = {Multi-{Objective} {Reinforcement} {Learning} {Based} on {Decomposition}},
	url = {http://arxiv.org/abs/2311.12495},
	doi = {10.48550/arXiv.2311.12495},
	abstract = {Multi-objective reinforcement learning (MORL) extends traditional RL by seeking policies making different compromises among conflicting objectives. The recent surge of interest in MORL has led to diverse studies and solving methods, often drawing from existing knowledge in multi-objective optimization based on decomposition (MOO/D). Yet, a clear categorization based on both RL and MOO/D is lacking in the existing literature. Consequently, MORL researchers face difficulties when trying to classify contributions within a broader context due to the absence of a standardized taxonomy. To tackle such an issue, this paper introduces multi-objective reinforcement learning based on decomposition (MORL/D), a novel methodology bridging the literature of RL and MOO. A comprehensive taxonomy for MORL/D is presented, providing a structured foundation for categorizing existing and potential MORL works. The introduced taxonomy is then used to scrutinize MORL research, enhancing clarity and conciseness through well-defined categorization. Moreover, a flexible framework derived from the taxonomy is introduced. This framework accommodates diverse instantiations using tools from both RL and MOO/D. Its versatility is demonstrated by implementing it in different configurations and assessing it on contrasting benchmark problems. Results indicate MORL/D instantiations achieve comparable performance to current state-of-the-art approaches on the studied problems. By presenting the taxonomy and framework, this paper offers a comprehensive perspective and a unified vocabulary for MORL. This not only facilitates the identification of algorithmic contributions but also lays the groundwork for novel research avenues in MORL.},
	urldate = {2025-09-15},
	publisher = {arXiv},
	author = {Felten, Florian and Talbi, El-Ghazali and Danoy, Grégoire},
	month = feb,
	year = {2024},
	note = {arXiv:2311.12495 [cs]},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: Accepted at JAIR},
}

@article{dash_review_2022,
	title = {A review of some techniques for inclusion of domain-knowledge into deep neural networks},
	volume = {12},
	copyright = {2022 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-021-04590-0},
	doi = {10.1038/s41598-021-04590-0},
	abstract = {We present a survey of ways in which existing scientific knowledge are included when constructing models with neural networks. The inclusion of domain-knowledge is of special interest not just to constructing scientific assistants, but also, many other areas that involve understanding data using human-machine collaboration. In many such instances, machine-based model construction may benefit significantly from being provided with human-knowledge of the domain encoded in a sufficiently precise form. This paper examines the inclusion of domain-knowledge by means of changes to: the input, the loss-function, and the architecture of deep networks. The categorisation is for ease of exposition: in practice we expect a combination of such changes will be employed. In each category, we describe techniques that have been shown to yield significant changes in the performance of deep neural networks.},
	language = {en},
	number = {1},
	urldate = {2025-09-15},
	journal = {Sci Rep},
	publisher = {Nature Publishing Group},
	author = {Dash, Tirtharaj and Chitlangia, Sharad and Ahuja, Aditya and Srinivasan, Ashwin},
	month = jan,
	year = {2022},
	keywords = {Computer science, Engineering, Information technology},
	pages = {1040},
}

@article{kusiak_convolutional_2020,
	title = {Convolutional and generative adversarial neural networks in manufacturing},
	volume = {58},
	issn = {0020-7543},
	url = {https://doi.org/10.1080/00207543.2019.1662133},
	doi = {10.1080/00207543.2019.1662133},
	abstract = {Manufacturing is undergoing transformation driven by the developments in process technology, information technology, and data science. A future manufacturing enterprise will be highly digital. This will create opportunities for machine learning algorithms to generate predictive models across the enterprise in the spirit of the digital twin concept. Convolutional and generative adversarial neural networks have received some attention of the manufacturing research community. Representative research and applications of the two machine learning concepts in manufacturing are presented. Advantages and limitations of each neural network are discussed. The paper might be helpful in identifying research gaps, inspire machine learning research in new manufacturing domains, contribute to the development of successful neural network architectures, and getting deeper insights into the manufacturing data.},
	number = {5},
	urldate = {2025-09-15},
	journal = {International Journal of Production Research},
	publisher = {Taylor \& Francis},
	author = {Kusiak, Andrew},
	month = mar,
	year = {2020},
	note = {\_eprint: https://doi.org/10.1080/00207543.2019.1662133},
	keywords = {machine learning, manufacturing, convolutional neural networks, deep learning, generative adversarial networks, intelligent manufacturing, smart manufacturing},
	pages = {1594--1604},
}

@article{franca_fast_2014,
	title = {Fast relational learning using bottom clause propositionalization with artificial neural networks},
	volume = {94},
	issn = {1573-0565},
	url = {https://doi.org/10.1007/s10994-013-5392-1},
	doi = {10.1007/s10994-013-5392-1},
	abstract = {Relational learning can be described as the task of learning first-order logic rules from examples. It has enabled a number of new machine learning applications, e.g. graph mining and link analysis. Inductive Logic Programming (ILP) performs relational learning either directly by manipulating first-order rules or through propositionalization, which translates the relational task into an attribute-value learning task by representing subsets of relations as features. In this paper, we introduce a fast method and system for relational learning based on a novel propositionalization called Bottom Clause Propositionalization (BCP). Bottom clauses are boundaries in the hypothesis search space used by ILP systems Progol and Aleph. Bottom clauses carry semantic meaning and can be mapped directly onto numerical vectors, simplifying the feature extraction process. We have integrated BCP with a well-known neural-symbolic system, C-IL2P, to perform learning from numerical vectors. C-IL2P uses background knowledge in the form of propositional logic programs to build a neural network. The integrated system, which we call CILP++, handles first-order logic knowledge and is available for download from Sourceforge. We have evaluated CILP++ on seven ILP datasets, comparing results with Aleph and a well-known propositionalization method, RSD. The results show that CILP++ can achieve accuracy comparable to Aleph, while being generally faster, BCP achieved statistically significant improvement in accuracy in comparison with RSD when running with a neural network, but BCP and RSD perform similarly when running with C4.5. We have also extended CILP++ to include a statistical feature selection method, mRMR, with preliminary results indicating that a reduction of more than 90 \% of features can be achieved with a small loss of accuracy.},
	language = {en},
	number = {1},
	urldate = {2025-09-15},
	journal = {Mach Learn},
	author = {França, Manoel V. M. and Zaverucha, Gerson and d’Avila Garcez, Artur S.},
	month = jan,
	year = {2014},
	keywords = {Inductive logic programming, Artificial neural networks, Neural-symbolic integration, Propositionalization, Relational learning},
	pages = {81--104},
}

@inproceedings{bordes_translating_2013,
	title = {Translating {Embeddings} for {Modeling} {Multi}-relational {Data}},
	volume = {26},
	url = {https://proceedings.neurips.cc/paper/2013/hash/1cecc7a77928ca8133fa24680a88d2f9-Abstract.html},
	abstract = {We consider the problem of embedding entities and relationships of multi-relational data in low-dimensional vector spaces. Our objective is to propose a canonical model which is easy to train, contains a reduced number of parameters and can scale up to very large databases. Hence, we propose, TransE, a method which models relationships by interpreting them as translations operating on the low-dimensional embeddings of the entities. Despite its simplicity, this assumption proves to be powerful since extensive experiments show that TransE significantly outperforms state-of-the-art methods in link prediction on two knowledge bases. Besides, it can be successfully trained on a large scale data set with 1M entities, 25k relationships and more than 17M training samples.},
	urldate = {2025-09-15},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Bordes, Antoine and Usunier, Nicolas and Garcia-Duran, Alberto and Weston, Jason and Yakhnenko, Oksana},
	year = {2013},
	keywords = {ORKG},
}

@article{ratner_snorkel_2017,
	title = {Snorkel: {Rapid} {Training} {Data} {Creation} with {Weak} {Supervision}},
	volume = {11},
	issn = {2150-8097},
	shorttitle = {Snorkel},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5951191/},
	doi = {10.14778/3157794.3157797},
	abstract = {Labeling training data is increasingly the largest bottleneck in deploying machine learning systems. We present Snorkel, a first-of-its-kind system that enables users to train state-of- the-art models without hand labeling any training data. Instead, users write labeling functions that express arbitrary heuristics, which can have unknown accuracies and correlations. Snorkel denoises their outputs without access to ground truth by incorporating the first end-to-end implementation of our recently proposed machine learning paradigm, data programming. We present a flexible interface layer for writing labeling functions based on our experience over the past year collaborating with companies, agencies, and research labs. In a user study, subject matter experts build models 2.8× faster and increase predictive performance an average 45.5\% versus seven hours of hand labeling. We study the modeling tradeoffs in this new setting and propose an optimizer for automating tradeoff decisions that gives up to 1.8× speedup per pipeline execution. In two collaborations, with the U.S. Department of Veterans Affairs and the U.S. Food and Drug Administration, and on four open-source text and image data sets representative of other deployments, Snorkel provides 132\% average improvements to predictive performance over prior heuristic approaches and comes within an average 3.60\% of the predictive performance of large hand-curated training sets.},
	number = {3},
	urldate = {2025-09-15},
	journal = {Proceedings VLDB Endowment},
	author = {Ratner, Alexander and Bach, Stephen H. and Ehrenberg, Henry and Fries, Jason and Wu, Sen and Ré, Christopher},
	month = nov,
	year = {2017},
	keywords = {ORKG},
	pages = {269--282},
}

@article{ioannidis_revel_2016,
	title = {{REVEL}: {An} {Ensemble} {Method} for {Predicting} the {Pathogenicity} of {Rare} {Missense} {Variants}},
	volume = {99},
	issn = {0002-9297, 1537-6605},
	shorttitle = {{REVEL}},
	url = {https://www.cell.com/ajhg/abstract/S0002-9297(16)30370-6},
	doi = {10.1016/j.ajhg.2016.08.016},
	language = {English},
	number = {4},
	urldate = {2025-09-15},
	journal = {The American Journal of Human Genetics},
	publisher = {Elsevier},
	author = {Ioannidis, Nilah M. and Rothstein, Joseph H. and Pejaver, Vikas and Middha, Sumit and McDonnell, Shannon K. and Baheti, Saurabh and Musolf, Anthony and Li, Qing and Holzinger, Emily and Karyadi, Danielle and Cannon-Albright, Lisa A. and Teerlink, Craig C. and Stanford, Janet L. and Isaacs, William B. and Xu, Jianfeng and Cooney, Kathleen A. and Lange, Ethan M. and Schleutker, Johanna and Carpten, John D. and Powell, Isaac J. and Cussenot, Olivier and Cancel-Tassin, Geraldine and Giles, Graham G. and MacInnis, Robert J. and Maier, Christiane and Hsieh, Chih-Lin and Wiklund, Fredrik and Catalona, William J. and Foulkes, William D. and Mandal, Diptasri and Eeles, Rosalind A. and Kote-Jarai, Zsofia and Bustamante, Carlos D. and Schaid, Daniel J. and Hastie, Trevor and Ostrander, Elaine A. and Bailey-Wilson, Joan E. and Radivojac, Predrag and Thibodeau, Stephen N. and Whittemore, Alice S. and Sieh, Weiva},
	month = oct,
	year = {2016},
	pages = {877--885},
}

@inproceedings{marino_krisp_2021,
	title = {{KRISP}: {Integrating} {Implicit} and {Symbolic} {Knowledge} for {Open}-{Domain} {Knowledge}-{Based} {VQA}},
	shorttitle = {{KRISP}},
	url = {https://openaccess.thecvf.com/content/CVPR2021/html/Marino_KRISP_Integrating_Implicit_and_Symbolic_Knowledge_for_Open-Domain_Knowledge-Based_VQA_CVPR_2021_paper.html?ref=https://githubhelp.com},
	language = {en},
	urldate = {2025-09-15},
	author = {Marino, Kenneth and Chen, Xinlei and Parikh, Devi and Gupta, Abhinav and Rohrbach, Marcus},
	year = {2021},
	pages = {14111--14121},
}

@article{cuomo_scientific_2022,
	title = {Scientific {Machine} {Learning} {Through} {Physics}–{Informed} {Neural} {Networks}: {Where} we are and {What}’s {Next}},
	volume = {92},
	issn = {1573-7691},
	shorttitle = {Scientific {Machine} {Learning} {Through} {Physics}–{Informed} {Neural} {Networks}},
	url = {https://doi.org/10.1007/s10915-022-01939-z},
	doi = {10.1007/s10915-022-01939-z},
	abstract = {Physics-Informed Neural Networks (PINN) are neural networks (NNs) that encode model equations, like Partial Differential Equations (PDE), as a component of the neural network itself. PINNs are nowadays used to solve PDEs, fractional equations, integral-differential equations, and stochastic PDEs. This novel methodology has arisen as a multi-task learning framework in which a NN must fit observed data while reducing a PDE residual. This article provides a comprehensive review of the literature on PINNs: while the primary goal of the study was to characterize these networks and their related advantages and disadvantages. The review also attempts to incorporate publications on a broader range of collocation-based physics informed neural networks, which stars form the vanilla PINN, as well as many other variants, such as physics-constrained neural networks (PCNN), variational hp-VPINN, and conservative PINN (CPINN). The study indicates that most research has focused on customizing the PINN through different activation functions, gradient optimization techniques, neural network structures, and loss function structures. Despite the wide range of applications for which PINNs have been used, by demonstrating their ability to be more feasible in some contexts than classical numerical techniques like Finite Element Method (FEM), advancements are still possible, most notably theoretical issues that remain unresolved.},
	language = {en},
	number = {3},
	urldate = {2025-09-15},
	journal = {J Sci Comput},
	author = {Cuomo, Salvatore and Di Cola, Vincenzo Schiano and Giampaolo, Fabio and Rozza, Gianluigi and Raissi, Maziar and Piccialli, Francesco},
	month = jul,
	year = {2022},
	keywords = {Deep Neural Networks, Nonlinear equations, Numerical methods, Partial Differential Equations, Physics–Informed Neural Networks, Scientific Machine Learning, Uncertainty},
	pages = {88},
}

@inproceedings{xu_semantic_2018,
	title = {A {Semantic} {Loss} {Function} for {Deep} {Learning} with {Symbolic} {Knowledge}},
	issn = {2640-3498},
	url = {https://proceedings.mlr.press/v80/xu18h.html},
	abstract = {This paper develops a novel methodology for using symbolic knowledge in deep learning. From first principles, we derive a semantic loss function that bridges between neural output vectors and logical constraints. This loss function captures how close the neural network is to satisfying the constraints on its output. An experimental evaluation shows that it effectively guides the learner to achieve (near-)state-of-the-art results on semi-supervised multi-class classification. Moreover, it significantly increases the ability of the neural network to predict structured objects, such as rankings and paths. These discrete concepts are tremendously difficult to learn, and benefit from a tight integration of deep learning and symbolic reasoning methods.},
	language = {en},
	urldate = {2025-09-15},
	booktitle = {Proceedings of the 35th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Xu, Jingyi and Zhang, Zilu and Friedman, Tal and Liang, Yitao and Broeck, Guy},
	month = jul,
	year = {2018},
	pages = {5502--5511},
}

@inproceedings{fischer_dl2_2019,
	title = {{DL2}: {Training} and {Querying} {Neural} {Networks} with {Logic}},
	issn = {2640-3498},
	shorttitle = {{DL2}},
	url = {https://proceedings.mlr.press/v97/fischer19a.html},
	abstract = {We present DL2, a system for training and querying neural networks with logical constraints. Using DL2, one can declaratively specify domain knowledge constraints to be enforced during training, as well as pose queries on the model to find inputs that satisfy a set of constraints. DL2 works by translating logical constraints into a loss function with desirable mathematical properties. The loss is then minimized with standard gradient-based methods. We evaluate DL2 by training networks with interesting constraints in unsupervised, semi-supervised and supervised settings. Our experimental evaluation demonstrates that DL2 is more expressive than prior approaches combining logic and neural networks, and its loss functions are better suited for optimization. Further, we show that for a number of queries, DL2 can find the desired inputs in seconds (even for large models such as ResNet-50 on ImageNet).},
	language = {en},
	urldate = {2025-09-15},
	booktitle = {Proceedings of the 36th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Fischer, Marc and Balunovic, Mislav and Drachsler-Cohen, Dana and Gehr, Timon and Zhang, Ce and Vechev, Martin},
	month = may,
	year = {2019},
	pages = {1931--1941},
}

@inproceedings{kaliszyk_holstep_2017,
	title = {{HolStep}: {A} {Machine} {Learning} {Dataset} for {Higher}-order {Logic} {Theorem} {Proving}},
	shorttitle = {{HolStep}},
	url = {https://openreview.net/forum?id=ryuxYmvel},
	abstract = {Large computer-understandable proofs consist of millions of intermediate logical steps. The vast majority of such steps originate from manually selected and manually guided heuristics applied to intermediate goals. So far, machine learning has generally not been used to filter or generate these steps. In this paper, we introduce a new dataset based on Higher-Order Logic (HOL) proofs, for the purpose of developing new machine learning-based theorem-proving strategies. We make this dataset publicly available under the BSD license. We propose various machine learning tasks that can be performed on this dataset, and discuss their significance for theorem proving. We also benchmark a set of simple baseline machine learning models suited for the tasks (including logistic regression convolutional neural networks and recurrent neural networks). The results of our baseline models show the promise of applying machine learning to HOL theorem proving.},
	language = {en},
	urldate = {2025-09-15},
	author = {Kaliszyk, Cezary and Chollet, François and Szegedy, Christian},
	month = feb,
	year = {2017},
	}

@inproceedings{mao_neuro-symbolic_2018,
	title = {The {Neuro}-{Symbolic} {Concept} {Learner}: {Interpreting} {Scenes}, {Words}, and {Sentences} {From} {Natural} {Supervision}},
	shorttitle = {The {Neuro}-{Symbolic} {Concept} {Learner}},
	url = {https://openreview.net/forum?id=rJgMlhRctm},
	abstract = {We propose the Neuro-Symbolic Concept Learner (NS-CL), a model that learns visual concepts, words, and semantic parsing of sentences without explicit supervision on any of them; instead, our model learns by simply looking at images and reading paired questions and answers. Our model builds an object-based scene representation and translates sentences into executable, symbolic programs. To bridge the learning of two modules, we use a neuro-symbolic reasoning module that executes these programs on the latent scene representation. Analogical to human concept learning, the perception module learns visual concepts based on the language description of the object being referred to. Meanwhile, the learned visual concepts facilitate learning new words and parsing new sentences. We use curriculum learning to guide the searching over the large compositional space of images and language. Extensive experiments demonstrate the accuracy and efficiency of our model on learning visual concepts, word representations, and semantic parsing of sentences. Further, our method allows easy generalization to new object attributes, compositions, language concepts, scenes and questions, and even new program domains. It also empowers applications including visual question answering and bidirectional image-text retrieval.},
	language = {en},
	urldate = {2026-01-06},
	author = {Mao, Jiayuan and Gan, Chuang and Kohli, Pushmeet and Tenenbaum, Joshua B. and Wu, Jiajun},
	month = sep,
	year = {2018},
	}

@inproceedings{luo_end--end_2024,
	title = {End-to-{End} {Neuro}-{Symbolic} {Reinforcement} {Learning} with {Textual} {Explanations}},
	issn = {2640-3498},
	url = {https://proceedings.mlr.press/v235/luo24j.html},
	abstract = {Neuro-symbolic reinforcement learning (NS-RL) has emerged as a promising paradigm for explainable decision-making, characterized by the interpretability of symbolic policies. NS-RL entails structured state representations for tasks with visual observations, but previous methods cannot refine the structured states with rewards due to a lack of efficiency. Accessibility also remains an issue, as extensive domain knowledge is required to interpret symbolic policies. In this paper, we present a neuro-symbolic framework for jointly learning structured states and symbolic policies, whose key idea is to distill the vision foundation model into an efficient perception module and refine it during policy learning. Moreover, we design a pipeline to prompt GPT-4 to generate textual explanations for the learned policies and decisions, significantly reducing users’ cognitive load to understand the symbolic policies. We verify the efficacy of our approach on nine Atari tasks and present GPT-generated explanations for policies and decisions.},
	language = {en},
	urldate = {2026-01-06},
	booktitle = {Proceedings of the 41st {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Luo, Lirui and Zhang, Guoxi and Xu, Hongming and Yang, Yaodong and Fang, Cong and Li, Qing},
	month = jul,
	year = {2024},
	pages = {33533--33557},
	}

@article{golpayegani_advancing_2024,
	title = {Advancing {Sustainable} {Manufacturing}: {Reinforcement} {Learning} with {Adaptive} {Reward} {Machine} {Using} an {Ontology}-{Based} {Approach}},
	volume = {16},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2071-1050},
	shorttitle = {Advancing {Sustainable} {Manufacturing}},
	url = {https://www.mdpi.com/2071-1050/16/14/5873},
	doi = {10.3390/su16145873},
	abstract = {Sustainable manufacturing practices are crucial in job shop scheduling (JSS) to enhance the resilience of production systems against resource shortage...},
	language = {en},
	number = {14},
	urldate = {2026-01-06},
	journal = {Sustainability},
	publisher = {publisher},
	author = {Golpayegani, Fatemeh and Ghanadbashi, Saeedeh and Zarchini, Akram and Golpayegani, Fatemeh and Ghanadbashi, Saeedeh and Zarchini, Akram},
	month = jul,
	year = {2024},
	note = {Company: Multidisciplinary Digital Publishing Institute
Distributor: Multidisciplinary Digital Publishing Institute
Institution: Multidisciplinary Digital Publishing Institute
Label: Multidisciplinary Digital Publishing Institute},
	keywords = {reinforcement learning, adaptive reward function, dynamic environments, job shop scheduling, multi-objective, ontology, partially observable environments, reward machines, sustainable manufacturing},
	}

@article{jacobson_integrating_2025,
	title = {Integrating symbolic reasoning into neural generative models for design generation},
	volume = {339},
	issn = {0004-3702},
	url = {https://www.sciencedirect.com/science/article/pii/S0004370224001930},
	doi = {10.1016/j.artint.2024.104257},
	abstract = {Design generation requires tight integration of neural and symbolic reasoning, as good design must meet explicit user needs and honor implicit rules for aesthetics, utility, and convenience. Current automated design tools driven by neural networks produce appealing designs, but cannot satisfy user specifications and utility requirements. Symbolic reasoning tools, such as constraint programming, cannot perceive low-level visual information in images or capture subtle aspects such as aesthetics. We introduce the Spatial Reasoning Integrated Generator (SPRING) for design generation. SPRING embeds a neural and symbolic integrated spatial reasoning module inside the deep generative network. The spatial reasoning module samples the set of locations of objects to be generated from a backtrack-free distribution. This distribution modifies the implicit preference distribution, which is learned by a recurrent neural network to capture utility and aesthetics. The sampling from the backtrack-free distribution is accomplished by a symbolic reasoning approach, SampleSearch, which zeros out the probability of sampling spatial locations violating explicit user specifications. Embedding symbolic reasoning into neural generation guarantees that the output of SPRING satisfies user requirements. Furthermore, SPRING offers interpretability, allowing users to visualize and diagnose the generation process through the bounding boxes. SPRING is also adept at managing novel user specifications not encountered during its training, thanks to its proficiency in zero-shot constraint transfer. Quantitative evaluations and a human study reveal that SPRING outperforms baseline generative models, excelling in delivering high design quality and better meeting user specifications.},
	urldate = {2026-01-06},
	journal = {Artificial Intelligence},
	author = {Jacobson, Maxwell J. and Xue, Yexiang},
	month = feb,
	year = {2025},
	keywords = {Constrained content generation, Constraint reasoning, Neural generative models},
	pages = {104257},
	}

@article{yan_periodic_2022,
	title = {Periodic {Graph} {Transformers} for {Crystal} {Material} {Property} {Prediction}},
	volume = {35},
	url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/6145c70a4a4bf353a31ac5496a72a72d-Abstract-Conference.html},
	language = {en},
	urldate = {2026-01-14},
	journal = {Advances in Neural Information Processing Systems},
	author = {Yan, Keqiang and Liu, Yi and Lin, Yuchao and Ji, Shuiwang},
	month = dec,
	year = {2022},
	pages = {15066--15080},
	}

@article{maciol_new_2025,
	title = {A new ontology-based approach to automatic information extraction from speech for production disturbance management},
	volume = {136},
	issn = {1433-3015},
	url = {https://doi.org/10.1007/s00170-025-15000-4},
	doi = {10.1007/s00170-025-15000-4},
	abstract = {The goal of our research was to design a methodology for extracting systematized knowledge from free speech. The sources of knowledge in our analysis were records of production meetings, focused on production disturbance (PD). The main obstacle is to properly identify the specific meaning of words, in a specific, usually narrow, industry. Machine learning based on data from production records has been increasingly used to build such models. In the case of manufacturing plants with diverse production programs, acquiring the right number and structure of data is not possible; hence, proper identification of such terms is for classical NLP tools, even supported by large language models, not possible. We have attempted to use AI and NLP tools from recorded production meeting recordings to create and continuously update PD’s knowledge as a supplement to data from documentation. This is an approach not previously known in the field of production management. The solution we developed consists of an expert-defined specific ontology, based on the pre-processed speeches. At this stage, a lexicon (vocabulary) is also created, supporting the transformation of the speeches into interpretable texts. The model ontology formulated this way is then used to analyze consecutively provided meeting records and thus update the operational ontology. In our research, we used the materials provided to us in the form of records of production meetings from a medium-sized pressure foundry. The obtained results confirm that the adopted knowledge model and the algorithms might be successfully utilized to solve real-world manufacturing problems.},
	language = {en},
	number = {7},
	urldate = {2026-01-14},
	journal = {Int J Adv Manuf Technol},
	author = {Macioł, Andrzej and Macioł, Piotr and Gumienny, Grzegorz and Wrzała, Konrad},
	month = feb,
	year = {2025},
	keywords = {Decision support systems, Natural language processing, NLP, Ontology, OWL, Production disturbance},
	pages = {3735--3752},
	}

@article{yang_ontology-based_2023,
	title = {Ontology-based knowledge representation of industrial production workflow},
	volume = {58},
	issn = {1474-0346},
	url = {https://www.sciencedirect.com/science/article/pii/S1474034623003130},
	doi = {10.1016/j.aei.2023.102185},
	abstract = {Industry 4.0 is helping to unleash a new age of digitalization across industries, leading to a data-driven, interoperable, and decentralized production process. To achieve this major transformation, one of the main requirements is to achieve interoperability across various systems and multiple devices. Ontologies have been used in numerous industrial projects to tackle the interoperability challenge in digital manufacturing. However, there is currently no semantic model in the literature that can be used to represent the industrial production workflow comprehensively while also integrating digitalized information from a variety of systems and contexts. To fill this gap, this paper proposed industrial production workflow ontologies (InPro) for formalizing and integrating production process information. We implemented the 5 M model (manpower, machine, material, method, and measurement) for InPro partitioning and module extraction. The InPro comprises seven main domain ontology modules including Entities, Agents, Machines, Materials, Methods, Measurements, and Production Processes. The Machines ontology module was developed leveraging the OPC Unified Architecture (OPC UA) information model. The presented InPro ontology was further evaluated by a hybrid combination of approaches. Additionally, the InPro ontology was implemented with practical use cases to support production planning and failure analysis by retrieving relevant information via SPARQL queries. The validation results also demonstrated that using the proposed InPro ontology allows for efficiently formalizing, integrating, and retrieving information within the industrial production process context.},
	urldate = {2026-01-14},
	journal = {Advanced Engineering Informatics},
	author = {Yang, Chao and Zheng, Yuan and Tu, Xinyi and Ala-Laurinaho, Riku and Autiosalo, Juuso and Seppänen, Olli and Tammi, Kari},
	month = oct,
	year = {2023},
	keywords = {Ontology, Knowledge representation, Production workflow, Semantic interoperability, System integration},
	pages = {102185},
	}

@misc{huang_material_2024,
	title = {Material {Property} {Prediction} with {Element} {Attribute} {Knowledge} {Graphs} and {Multimodal} {Representation} {Learning}},
	url = {http://arxiv.org/abs/2411.08414},
	doi = {10.48550/arXiv.2411.08414},
	abstract = {Machine learning has become a crucial tool for predicting the properties of crystalline materials. However, existing methods primarily represent material information by constructing multi-edge graphs of crystal structures, often overlooking the chemical and physical properties of elements (such as atomic radius, electronegativity, melting point, and ionization energy), which have a significant impact on material performance. To address this limitation, we first constructed an element property knowledge graph and utilized an embedding model to encode the element attributes within the knowledge graph. Furthermore, we propose a multimodal fusion framework, ESNet, which integrates element property features with crystal structure features to generate joint multimodal representations. This provides a more comprehensive perspective for predicting the performance of crystalline materials, enabling the model to consider both microstructural composition and chemical characteristics of the materials. We conducted experiments on the Materials Project benchmark dataset, which showed leading performance in the bandgap prediction task and achieved results on a par with existing benchmarks in the formation energy prediction task.},
	urldate = {2026-01-14},
	publisher = {arXiv},
	author = {Huang, Chao and Chen, Chunyan and Shi, Ling and Chen, Chen},
	month = nov,
	year = {2024},
	note = {arXiv:2411.08414 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Condensed Matter - Materials Science},
}

@misc{wu_nesygeo_2025,
	title = {{NeSyGeo}: {A} {Neuro}-{Symbolic} {Framework} for {Multimodal} {Geometric} {Reasoning} {Data} {Generation}},
	shorttitle = {{NeSyGeo}},
	url = {http://arxiv.org/abs/2505.17121},
	doi = {10.48550/arXiv.2505.17121},
	abstract = {Obtaining large-scale, high-quality reasoning data is crucial for improving the geometric reasoning capabilities of multi-modal large language models (MLLMs). However, existing data generation methods, whether based on predefined tem plates or constrained symbolic provers, inevitably face diversity and numerical generalization limitations. To address these limitations, we propose NeSyGeo, a novel neuro-symbolic framework for generating geometric reasoning data. First, we propose a domain-specific language grounded in the entity-attributes-relations paradigm to comprehensively represent all components of plane geometry, along with generative actions defined within this symbolic space. We then design a symbolic-visual-text pipeline that synthesizes symbolic sequences, maps them to visual and textual representations and generates reasoning path with reverse search and forward validation. Based on this framework, we construct NeSyGeo CoT and NeSyGeo-Caption datasets, containing 100k samples, and release a new benchmark NeSyGeo-Test for evaluating geometric reasoning abilities in MLLMs. Experiments demonstrate that the proposal significantly and consistently improves the performance of multiple MLLMs under both reinforcement and supervised fine-tuning. With only 4k samples and two epochs of reinforcement fine-tuning, base models achieve improvements of up to +15.8\% on MathVision, +8.4\% on MathVerse, and +7.3\% on GeoQA. Notably, a 4B model can be improved to outperform an 8B model from the same series on geometric reasoning tasks.s},
	urldate = {2026-01-14},
	publisher = {arXiv},
	author = {Wu, Weiming and Ye, Jin and Wang, Zi-kang and Zhou, Zhi and Li, Yu-Feng and Guo, Lan-Zhe},
	month = oct,
	year = {2025},
	note = {arXiv:2505.17121 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	annote = {Comment: 29 pages},
}

@article{li_llm4cad_2024,
	title = {{LLM4CAD}: {Multimodal} {Large} {Language} {Models} for {Three}-{Dimensional} {Computer}-{Aided} {Design} {Generation}},
	volume = {25},
	issn = {1530-9827},
	shorttitle = {{LLM4CAD}},
	url = {https://doi.org/10.1115/1.4067085},
	doi = {10.1115/1.4067085},
	abstract = {The evolution of multimodal large language models (LLMs) capable of processing diverse input modalities (e.g., text and images) holds new prospects for their application in engineering design, such as the generation of 3D computer-aided design (CAD) models. However, little is known about the ability of multimodal LLMs to generate 3D design objects, and there is a lack of quantitative assessment. In this study, we develop an approach to enable LLMs to generate 3D CAD models (i.e., LLM4CAD) and perform experiments to evaluate their efficacy where GPT-4 and GPT-4V were employed as examples. To address the challenge of data scarcity for multimodal LLM studies, we created a data synthesis pipeline to generate CAD models, sketches, and image data of typical mechanical components (e.g., gears and springs) and collect their natural language descriptions with dimensional information using Amazon Mechanical Turk. We positioned the CAD program (programming script for CAD design) as a bridge, facilitating the conversion of LLMs’ textual output into tangible CAD design objects. We focus on two critical capabilities: the generation of syntactically correct CAD programs (Cap1) and the accuracy of the parsed 3D shapes (Cap2) quantified by intersection over union. The results show that both GPT-4 and GPT-4V demonstrate great potential in 3D CAD generation by just leveraging their zero-shot learning ability. Specifically, on average, GPT-4V outperforms when processing only text-based input, exceeding the results obtained using multimodal inputs, such as text with image, for Cap 1 and Cap 2. However, when examining category-specific results of mechanical components, the prominence of multimodal inputs is increasingly evident for more complex geometries (e.g., springs and gears) in both Cap 1 and Cap 2. The potential of multimodal LLMs to improve 3D CAD generation is clear, but their application must be carefully calibrated to the complexity of the target CAD models to be generated.},
	number = {021005},
	urldate = {2026-01-14},
	journal = {J. Comput. Inf. Sci. Eng},
	author = {Li, Xingang and Sun, Yuewan and Sha, Zhenghui},
	month = dec,
	year = {2024},
}

@article{yuan_openecad_2024,
	title = {{OpenECAD}: {An} efficient visual language model for editable {3D}-{CAD} design},
	volume = {124},
	issn = {0097-8493},
	shorttitle = {{OpenECAD}},
	url = {https://www.sciencedirect.com/science/article/pii/S0097849324001833},
	doi = {10.1016/j.cag.2024.104048},
	abstract = {Computer-aided design (CAD) tools are utilized in the manufacturing industry for modeling everything from cups to spacecraft. These programs are complex to use and typically require years of training and experience to master. Structured and well-constrained 2D sketches and 3D constructions are crucial components of CAD modeling. A well-executed CAD model can be seamlessly integrated into the manufacturing process, thereby enhancing production efficiency. Deep generative models of 3D shapes and 3D object reconstruction models have garnered significant research interest. However, most of these models produce discrete forms of 3D objects that are not editable. Moreover, the few models based on CAD operations often have substantial input restrictions. In this work, we fine-tuned pre-trained models to create OpenECAD models (0.55B, 0.89B, 2.4B and 3.1B), leveraging the visual, logical, coding, and general capabilities of visual language models. OpenECAD models can process images of 3D designs as input and generate highly structured 2D sketches and 3D construction commands, ensuring that the designs are editable. These outputs can be directly used with existing CAD tools’ APIs to generate project files. To train our network, we created a series of OpenECAD datasets. These datasets are derived from existing public CAD datasets, adjusted and augmented to meet the specific requirements of vision language model (VLM) training. Additionally, we have introduced an approach that utilizes dependency relationships to define and generate sketches, further enriching the content and functionality of the datasets.},
	urldate = {2026-01-14},
	journal = {Computers \& Graphics},
	author = {Yuan, Zhe and Shi, Jianqi and Huang, Yanhong},
	month = nov,
	year = {2024},
	keywords = {Computer aided design, Geometric deep learning, Small language model, Visual language model},
	pages = {104048},
  }

@inproceedings{tian_asap_2024,
	title = {{ASAP}: {Automated} {Sequence} {Planning} for {Complex} {Robotic} {Assembly} with {Physical} {Feasibility}},
	shorttitle = {{ASAP}},
	url = {https://ieeexplore.ieee.org/abstract/document/10611595},
	doi = {10.1109/ICRA57147.2024.10611595},
	abstract = {The automated assembly of complex products requires a system that can automatically plan a physically feasible sequence of actions for assembling many parts together. In this paper, we present ASAP, a physics-based planning approach for automatically generating such a sequence for general-shaped assemblies. ASAP accounts for gravity to design a sequence where each sub-assembly is physically stable with a limited number of parts being held and a support surface. We apply efficient tree search algorithms to reduce the combinatorial complexity of determining such an assembly sequence. The search can be guided by either geometric heuristics or graph neural networks trained on data with simulation labels. Finally, we show the superior performance of ASAP at generating physically realistic assembly sequence plans on a large dataset of hundreds of complex product assemblies. We further demonstrate the applicability of ASAP on both simulation and real-world robotic setups. Project website: asap.csail.mit.edu},
	urldate = {2026-01-14},
	booktitle = {2024 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Tian, Yunsheng and Willis, Karl D. D. and Al Omari, Bassel and Luo, Jieliang and Ma, Pingchuan and Li, Yichen and Javid, Farhad and Gu, Edward and Jacob, Joshua and Sueda, Shinjiro and Li, Hui and Chitta, Sachin and Matusik, Wojciech},
	month = may,
	year = {2024},
	keywords = {Robots, Graph neural networks, Assembly, Complexity theory, Gravity, Planning, Robotic assembly},
	pages = {4380--4386},
}

@misc{noauthor_safe_nodate,
	title = {Safe {Reinforcement} {Learning} via {Shielding} under {Partial} {Observability} {\textbar} {Proceedings} of the {AAAI} {Conference} on {Artificial} {Intelligence}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/26723},
	urldate = {2026-01-14},
}

@article{odriozola-olalde_towards_2025,
	title = {Towards robust shielded reinforcement learning through adaptive constraints and exploration: {The} fear field framework},
	volume = {144},
	issn = {0952-1976},
	shorttitle = {Towards robust shielded reinforcement learning through adaptive constraints and exploration},
	url = {https://www.sciencedirect.com/science/article/pii/S0952197625000557},
	doi = {10.1016/j.engappai.2025.110055},
	abstract = {Machine Learning (ML) techniques, including Reinforcement Learning (RL), demonstrate potential as decision-making controllers. However, enhancing the robustness required for real-world deployment remains imperative. Within the realm of Safe RL, Shielded RL emerges as a solution, employing shields to block actions leading to unsafe states and offering safe alternatives through known policies. Yet, many Shielded RL methods rely on dynamic environment models, which may inaccurately predict future states, compromising controller robustness. We introduce the Fear Field framework to mitigate this issue for discrete Markov Decision Process-based (MDP) shields with strictly connected unsafe state spaces and fully observable states, which adjusts safe operation constraints based on disparities between model predictions and actual environmental dynamics. We employ parallel learning and Curriculum Learning (CL) strategies to mitigate lengthy training times in high state-space size environments. Additionally, an adaptive exploration algorithm enhances convergence rates amidst significant environmental dynamic shifts. In our case study, integrating CL and the adaptive exploration algorithm with the Fear Field framework reduces unsafe state occurrences by two orders of magnitude while enhancing convergence time following sudden environmental changes. The Fear Field framework significantly reduces unsafe states in the Frozen Lake Gridworld environment at low computational expense when model predictions deviate from reality, with negligible costs otherwise.},
	urldate = {2026-01-14},
	journal = {Engineering Applications of Artificial Intelligence},
	author = {Odriozola-Olalde, Haritz and Zamalloa, Maider and Arana-Arexolaleiba, Nestor and Perez-Cerrolaza, Jon},
	month = mar,
	year = {2025},
	keywords = {Robustness, Adaptive exploration, Curriculum learning, Fear Field, Safety constraints, Shielded reinforcement learning},
	pages = {110055},
}

@article{wang_mcgan_2025,
	title = {{McGAN}: {Generating} manufacturable designs by embedding manufacturing rules into conditional generative adversarial network},
	volume = {64},
	issn = {1474-0346},
	shorttitle = {{McGAN}},
	url = {https://www.sciencedirect.com/science/article/pii/S1474034624007250},
	doi = {10.1016/j.aei.2024.103074},
	abstract = {Generative design (GD) methods aim to automatically generate a wide variety of designs that satisfy functional or aesthetic design requirements. However, research to date generally lacks considerations of manufacturability of the generated designs. To this end, we propose a novel GD approach by using deep neural networks to encode design for manufacturing (DFM) rules, thereby modifying part designs to make them manufacturable by a given manufacturing process. Specifically, a three-step approach is proposed: first, an instance segmentation method, Mask R-CNN, is used to decompose a part design into subregions. Second, a conditional generative adversarial neural network (cGAN), Pix2Pix, transforms unmanufacturable decomposed subregions into manufacturable subregions. The transformed subregions of designs are subsequently reintegrated into a unified manufacturable design. These three steps, Mask-RCNN, Pix2Pix, and reintegration, form the basis of the proposed Manufacturable conditional GAN (McGAN) framework. Experimental results show that McGAN can transform existing unmanufacturable designs to generate their corresponding manufacturable counterparts automatically that realize the specified manufacturing rules in an efficient and robust manner. The effectiveness of McGAN is demonstrated through two-dimensional design case studies focused on the injection molding process, with the potential to generalize across different manufacturing processes for both 2D and 3D input data.},
	urldate = {2026-01-14},
	journal = {Advanced Engineering Informatics},
	author = {Wang, Zhichao and Yan, Xiaoliang and Melkote, Shreyes and Rosen, David},
	month = mar,
	year = {2025},
	keywords = {Design for manufacturing, Generative design, Image-to-image translation, Instance segmentation},
	pages = {103074},
}

@article{dong_neurcadrecon_2024,
	title = {{NeurCADRecon}: {Neural} {Representation} for {Reconstructing} {CAD} {Surfaces} by {Enforcing} {Zero} {Gaussian} {Curvature}},
	volume = {43},
	issn = {0730-0301},
	shorttitle = {{NeurCADRecon}},
	url = {https://dl.acm.org/doi/10.1145/3658171},
	doi = {10.1145/3658171},
	abstract = {Despite recent advances in reconstructing an organic model with the neural signed distance function (SDF), the high-fidelity reconstruction of a CAD model directly from low-quality unoriented point clouds remains a significant challenge. In this paper, we address this challenge based on the prior observation that the surface of a CAD model is generally composed of piecewise surface patches, each approximately developable even around the feature line. Our approach, named NeurCADRecon, is self-supervised, and its loss includes a developability term to encourage the Gaussian curvature toward 0 while ensuring fidelity to the input points (see the teaser figure). Noticing that the Gaussian curvature is non-zero at tip points, we introduce a double-trough curve to tolerate the existence of these tip points. Furthermore, we develop a dynamic sampling strategy to deal with situations where the given points are incomplete or too sparse. Since our resulting neural SDFs can clearly manifest sharp feature points/lines, one can easily extract the feature-aligned triangle mesh from the SDF and then decompose it into smooth surface patches, greatly reducing the difficulty of recovering the parametric CAD design. A comprehensive comparison with existing state-of-the-art methods shows the significant advantage of our approach in reconstructing faithful CAD shapes.},
	number = {4},
	urldate = {2026-01-14},
	journal = {ACM Trans. Graph.},
	author = {Dong, Qiujie and Xu, Rui and Wang, Pengfei and Chen, Shuangmin and Xin, Shiqing and Jia, Xiaohong and Wang, Wenping and Tu, Changhe},
	month = jul,
	year = {2024},
	pages = {51:1--51:17},
}

@inproceedings{berzins_geometry-informed_2025,
	title = {Geometry-{Informed} {Neural} {Networks}},
	url = {https://openreview.net/forum?id=o4KpjiCdrk},
	abstract = {Geometry is a ubiquitous tool in computer graphics, design, and engineering. However, the lack of large shape datasets limits the application of state-of-the-art supervised learning methods and motivates the exploration of alternative learning strategies. To this end, we introduce geometry-informed neural networks (GINNs) -- a framework for training shape-generative neural fields without data by leveraging user-specified design requirements in the form of objectives and constraints. By adding diversity as an explicit constraint, GINNs avoid mode-collapse and can generate multiple diverse solutions, often required in geometry tasks. Experimentally, we apply GINNs to several problems spanning physics, geometry, and engineering design, showing control over geometrical and topological properties, such as surface smoothness or the number of holes. These results demonstrate the potential of training shape-generative models without data, paving the way for new generative design approaches without large datasets.},
	language = {en},
	urldate = {2026-01-14},
	author = {Berzins, Arturs and Radler, Andreas and Volkmann, Eric and Sanokowski, Sebastian and Hochreiter, Sepp and Brandstetter, Johannes},
	month = jun,
	year = {2025},
	}

@article{jeong_complete_2023,
	title = {A complete {Physics}-{Informed} {Neural} {Network}-based framework for structural topology optimization},
	volume = {417},
	issn = {0045-7825},
	url = {https://www.sciencedirect.com/science/article/pii/S004578252300525X},
	doi = {10.1016/j.cma.2023.116401},
	abstract = {Physics-Informed Neural Networks (PINNs) have recently gained increasing attention in the field of topology optimization. The fusion of deep learning and topology optimization has emerged as a prominent area of insightful research, where minimization of the loss function in neural networks can be comparable to minimization of the objective function in topology optimization. Inspired by concepts of PINNs, this paper proposes a novel framework, ‘Complete Physics-Informed Neural Network-based Topology Optimization (CPINNTO)’, to address various challenges in topology optimization, particularly related to structural optimization. The key innovation of the proposed framework lies in introducing the first complete machine-learning-based topology optimization framework through integration of two distinct PINNs. Herein, the Deep Energy Method (DEM) PINN is implemented to determine the deformation state of corresponding structures numerically. In addition, derivation of the objective function with respect to design variables is replaced with automatic differentiation in sensitivity-analysis PINN (S-PINN). The feasibility and potential of the CPINNTO framework have been assessed through several case studies while highlighting strengths and limitations of utilizing PINNs in topology optimization. Subsequent findings indicate that CPINNTO can achieve optimal topologies without labeled data nor FEA. The numerical examples demonstrate that CPINNTO is capable of stably obtaining optimal structures for various topology optimization applications, including compliance minimization problems, multi-constrained problems, and three-dimensional problems. Resulting designs exhibit favorable compliance values comparable to the designs obtained via density-based topology optimization. In summary, the proposed CPINNTO framework opens up novel and interesting possibilities for structural topology optimization.},
	urldate = {2026-01-14},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Jeong, Hyogu and Batuwatta-Gamage, Chanaka and Bai, Jinshuai and Xie, Yi Min and Rathnayaka, Charith and Zhou, Ying and Gu, YuanTong},
	month = dec,
	year = {2023},
	keywords = {Machine learning, Design optimizations, Physics informed neural networks, Solid mechanics, Topology optimization},
	pages = {116401},
	}

@inproceedings{amos_optnet_2017,
	title = {{OptNet}: {Differentiable} {Optimization} as a {Layer} in {Neural} {Networks}},
	issn = {2640-3498},
	shorttitle = {{OptNet}},
	url = {https://proceedings.mlr.press/v70/amos17a.html},
	abstract = {This paper presents OptNet, a network architecture that integrates optimization problems (here, specifically in the form of quadratic programs) as individual layers in larger end-to-end trainable deep networks. These layers encode constraints and complex dependencies between the hidden states that traditional convolutional and fully-connected layers often cannot capture. In this paper, we explore the foundations for such an architecture: we show how techniques from sensitivity analysis, bilevel optimization, and implicit differentiation can be used to exactly differentiate through these layers and with respect to layer parameters; we develop a highly efficient solver for these layers that exploits fast GPU-based batch solves within a primal-dual interior point method, and which provides backpropagation gradients with virtually no additional cost on top of the solve; and we highlight the application of these approaches in several problems. In one notable example, we show that the method is capable of learning to play mini-Sudoku (4x4) given just input and output games, with no a priori information about the rules of the game; this highlights the ability of our architecture to learn hard constraints better than other neural architectures.},
	language = {en},
	urldate = {2026-01-14},
	booktitle = {Proceedings of the 34th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Amos, Brandon and Kolter, J. Zico},
	month = jul,
	year = {2017},
	pages = {136--145},
}

@inproceedings{agrawal_differentiable_2019,
	title = {Differentiable {Convex} {Optimization} {Layers}},
	volume = {32},
	url = {https://papers.neurips.cc/paper_files/paper/2019/hash/9ce3c52fc54362e22053399d3181c638-Abstract.html},
	urldate = {2026-01-14},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Agrawal, Akshay and Amos, Brandon and Barratt, Shane and Boyd, Stephen and Diamond, Steven and Kolter, J. Zico},
	year = {2019},
	}

@article{deva_prasad_nurbs-diff_2022,
	title = {{NURBS}-{Diff}: {A} {Differentiable} {Programming} {Module} for {NURBS}},
	volume = {146},
	issn = {0010-4485},
	shorttitle = {{NURBS}-{Diff}},
	url = {https://www.sciencedirect.com/science/article/pii/S0010448522000045},
	doi = {10.1016/j.cad.2022.103199},
	abstract = {Boundary representations (B-reps) using Non-Uniform Rational B-splines (NURBS) are the de facto standard used in CAD, but their utility in deep learning-based approaches is not well researched. We propose a differentiable NURBS module to integrate NURBS representations of CAD models with deep learning methods. We mathematically define the derivatives of the NURBS curves or surfaces with respect to the input parameters (control points, weights, and the knot vector). These derivatives are used to define an approximate Jacobian used for performing the “backward” evaluation to train the deep learning models. We have implemented our NURBS module using GPU-accelerated algorithms and integrated it with PyTorch, a popular deep learning framework. We demonstrate the efficacy of our NURBS module in performing CAD operations such as curve or surface fitting and surface offsetting. Further, we show its utility in deep learning for unsupervised point cloud reconstruction and enforce analysis constraints. These examples show that our module performs better for certain deep learning frameworks and can be directly integrated with any deep-learning framework requiring NURBS.},
	urldate = {2026-01-14},
	journal = {Computer-Aided Design},
	author = {Deva Prasad, Anjana and Balu, Aditya and Shah, Harshil and Sarkar, Soumik and Hegde, Chinmay and Krishnamurthy, Adarsh},
	month = may,
	year = {2022},
	keywords = {Geometric deep learning, Differentiable NURBS module, NURBS, Surface modeling},
	pages = {103199},
	}

@misc{he_embodied_2025,
	title = {Embodied {Intelligence} in {Disassembly}: {Multimodal} {Perception} {Cross}-validation and {Continual} {Learning} in {Neuro}-{Symbolic} {TAMP}},
	url = {https://arxiv.org/abs/2509.11270},
	author = {He, Ziwen and Wang, Zhigang and Peng, Yanlong and Chang, Pengxu and Yang, Hong and Chen, Ming},
	year = {2025},
	note = {\_eprint: 2509.11270},
}

@article{capitanelli_framework_2024,
	title = {A framework for neurosymbolic robot action planning using large language models},
	volume = {Volume 18 - 2024},
	issn = {1662-5218},
	url = {https://www.frontiersin.org/journals/neurorobotics/articles/10.3389/fnbot.2024.1342786},
	doi = {10.3389/fnbot.2024.1342786},
	journal = {Frontiers in Neurorobotics},
	author = {Capitanelli, Alessio and Mastrogiovanni, Fulvio},
	year = {2024},
}

@article{aeronautiques_pddlplanning_1998,
	title = {Pddl—the planning domain definition language},
	journal = {Technical Report, Tech. Rep.},
	author = {Aeronautiques, Constructions and Howe, Adele and Knoblock, Craig and McDermott, ISI Drew and Ram, Ashwin and Veloso, Manuela and Weld, Daniel and Sri, David Wilkins and Barrett, Anthony and Christianson, Dave and {others}},
	year = {1998},
}

@article{zhang_assembly_2022,
	title = {Assembly sequence planning: {A} review},
	volume = {15},
	url = {https://www.benthamdirect.com/content/journals/rascs/10.2174/2666255813999201002150656},
	number = {4},
	journal = {Recent Advances in Computer Science and Communications (Formerly: Recent Patents on Computer Science)},
	publisher = {Bentham Science Publishers direct},
	author = {Zhang, Han-Ye},
	year = {2022},
	pages = {531--539},
}

@misc{demoly_ontological_2019,
	title = {Ontological engineering for supporting semantic reasoning in design: deriving models based on ontologies for supporting engineering design},
	url = {https://www.tandfonline.com/doi/pdf/10.1080/09544828.2019.1633626},
	publisher = {Taylor \& Francis},
	author = {Demoly, Frédéric and Kim, Kyoung-Yun and Horváth, Imre},
	year = {2019},
	note = {Issue: 10-12
Pages: 405–416
Publication Title: Journal of engineering design
Volume: 30},
}

@article{li_ontology-based_2018,
	title = {An ontology-based product design framework for manufacturability verification and knowledge reuse},
	volume = {99},
	url = {https://link.springer.com/content/pdf/10.1007/s00170-018-2099-2.pdf},
	number = {9},
	journal = {The International Journal of Advanced Manufacturing Technology},
	publisher = {Springer},
	author = {Li, Zhi and Zhou, Xiaowu and Wang, WM and Huang, George and Tian, Zonggui and Huang, Shaowei},
	year = {2018},
	pages = {2121--2135},
}

@incollection{tarski_concept_1983,
	address = {Indianapolis, IN},
	edition = {2nd},
	title = {On the {Concept} of {Logical} {Consequence}},
	booktitle = {Logic, {Semantics}, {Metamathematics}: {Papers} from 1923 to 1938},
	publisher = {Hackett Publishing Company},
	author = {Tarski, Alfred},
	year = {1983},
	annote = {Original work published 1936},
}

@article{hamilton_is_2022,
	title = {Is {Neuro}-{Symbolic} {AI} {Meeting} its {Promises} in {Natural} {Language} {Processing}? {A} {Structured} {Review}},
	url = {https://www.semantic-web-journal.net/system/files/swj3228.pdf},
	journal = {Semantic Web – Interoperability, Usability, Applicability},
	author = {Hamilton, Kyle and Nayak, Aparna and Božić, Bojan and Longo, Luca},
	year = {2022},
}

@article{liang_ai_2025,
	title = {{AI} {Reasoning} in {Deep} {Learning} {Era}: {From} {Symbolic} {AI} to {Neural}–{Symbolic} {AI}},
	volume = {13},
	url = {https://www.mdpi.com/2227-7390/13/11/1707},
	number = {11},
	journal = {Mathematics},
	publisher = {MDPI},
	author = {Liang, Baoyu and Wang, Yuchen and Tong, Chao},
	year = {2025},
	pages = {1707},
}

@article{bader_dimensions_2005,
	title = {Dimensions of neural-symbolic integration-a structured survey},
	url = {https://arxiv.org/pdf/cs/0511042},
	journal = {arXiv preprint cs/0511042},
	author = {Bader, Sebastian and Hitzler, Pascal},
	year = {2005},
}

@misc{singh_neuro-symbolic_2023,
	title = {Neuro-{Symbolic} {RDF} and {Description} {Logic} {Reasoners}: {The} {State}-{Of}-{The}-{Art} and {Challenges}},
	url = {https://arxiv.org/abs/2308.04814},
	author = {Singh, Gunjan and Bhatia, Sumit and Mutharaju, Raghava},
	year = {2023},
	note = {\_eprint: 2308.04814},
}

@article{hohenecker_ontology_2020,
	title = {Ontology reasoning with deep neural networks},
	volume = {68},
	journal = {Journal of Artificial Intelligence Research},
	author = {Hohenecker, Patrick and Lukasiewicz, Thomas},
	year = {2020},
	pages = {503--540},
}

@article{ghanadbashi_using_2022,
	title = {Using ontology to guide reinforcement learning agents in unseen situations: {A} traffic signal control system case study},
	volume = {52},
	number = {2},
	journal = {Applied Intelligence},
	publisher = {Springer},
	author = {Ghanadbashi, Saeedeh and Golpayegani, Fatemeh},
	year = {2022},
	pages = {1808--1824},
}

@book{spivak_category_2014,
	title = {Category theory for the sciences},
	publisher = {MIT press},
	author = {Spivak, David I},
	year = {2014},
}

@article{brachman_overview_1985,
	title = {An {Overview} of the {KL}-{ONE} {Knowledge} {Representation} {System}},
	volume = {9},
	doi = {10.1207/s15516709cog0902_1},
	number = {2},
	journal = {Cognitive Science},
	publisher = {Wiley},
	author = {Brachman, Ronald J. and Schmolze, James G.},
	year = {1985},
	pages = {171--216},
}

@inproceedings{brachman_tractability_1984,
	address = {Austin, TX},
	title = {The {Tractability} of {Subsumption} in {Frame}-{Based} {Description} {Languages}},
	url = {https://www.aaai.org/Papers/AAAI/1984/AAAI84-007.pdf},
	booktitle = {Proceedings of the {National} {Conference} on {Artificial} {Intelligence} ({AAAI})},
	publisher = {AAAI Press},
	author = {Brachman, Ronald J. and Levesque, Hector J.},
	year = {1984},
	pages = {34--37},
}

@article{schmidt-schaus_attributive_1991,
	title = {Attributive {Concept} {Descriptions} with {Complements}},
	volume = {48},
	doi = {https://doi.org/10.1016/0004-3702(91)90078-X},
	number = {1},
	journal = {Artificial Intelligence},
	publisher = {Elsevier},
	author = {Schmidt-Schauß, Manfred and Smolka, Gert},
	year = {1991},
	pages = {1--26},
}

@article{baader_overview_2001,
	title = {An {Overview} of {Tableau} {Algorithms} for {Description} {Logics}},
	volume = {69},
	doi = {10.1023/A:1012552523893},
	number = {1},
	journal = {Studia Logica},
	publisher = {Springer},
	author = {Baader, Franz and Sattler, Ulrike},
	year = {2001},
	pages = {5--40},
}

@inproceedings{carral_combined_2018,
	title = {The combined approach to query answering in {Horn}-{ALCHOIQ}},
	booktitle = {{KR}},
	author = {Carral, David and Dragoste, Irina and Krötzsch, Markus},
	year = {2018},
	pages = {339--348},
}

@article{artale_dl-lite_2009,
	title = {The {DL}-{Lite} family and relations},
	volume = {36},
	journal = {Journal of artificial intelligence research},
	author = {Artale, Alessandro and Calvanese, Diego and Kontchakov, Roman and Zakharyaschev, Michael},
	year = {2009},
	pages = {1--69},
}

@inproceedings{baader_pushing_2005,
	title = {Pushing the {EL} {Envelope}},
	booktitle = {Proceedings of the 19th {International} {Joint} {Conference} on {Artificial} {Intelligence} ({IJCAI} 2005)},
	author = {Baader, Franz and Brandt, Sebastian and Lutz, Carsten},
	year = {2005},
	pages = {364--369},
}

@misc{motik_owl_2012,
	title = {{OWL} 2 {Web} {Ontology} {Language} {Profiles} ({Second} {Edition})},
	url = {https://www.w3.org/TR/owl2-profiles/},
	publisher = {World Wide Web Consortium (W3C)},
	author = {Motik, Boris and Patel-Schneider, Peter F. and Grau (eds.), Bernardo Cuenca},
	month = dec,
	year = {2012},
	annote = {W3C Recommendation},
}

@misc{motik_owl_2012-1,
	title = {{OWL} 2 {Web} {Ontology} {Language} {Document} {Overview} ({Second} {Edition}) — {OWL} 2 {DL}},
	url = {https://www.w3.org/TR/owl2-overview/},
	publisher = {World Wide Web Consortium (W3C)},
	author = {Motik, Boris and Patel-Schneider, Peter F. and Grau (eds.), Bernardo Cuenca},
	month = dec,
	year = {2012},
	annote = {W3C Recommendation},
}

@inproceedings{horrocks_even_2006,
	title = {The {Even} {More} {Irresistible} {SROIQ}},
	booktitle = {Proceedings of the 10th {International} {Conference} on {Principles} of {Knowledge} {Representation} and {Reasoning} ({KR} 2006)},
	publisher = {AAAI Press},
	author = {Horrocks, Ian and Kutz, Oliver and Sattler, Ulrike},
	year = {2006},
	pages = {57--67},
}

@incollection{reisig_placetransition_1987,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Place/{Transition} {Systems}: {The} {Formal} {Model}},
	volume = {254},
	isbn = {978-3-540-17906-9},
	url = {https://doi.org/10.1007/3-540-17906-2\_2},
	doi = {10.1007/3-540-17906-2_2},
	booktitle = {Petri {Nets}: {Central} {Models} and {Their} {Properties}},
	publisher = {Springer},
	author = {Reisig, Wolfgang},
	editor = {Reisig, Wolfgang and Rozenberg, Grzegorz},
	year = {1987},
	pages = {5--29},
}

@article{peterson_petri_1977,
	title = {Petri {Nets}},
	volume = {9},
	url = {https://doi.org/10.1145/356698.356702},
	doi = {10.1145/356698.356702},
	number = {3},
	journal = {ACM Computing Surveys},
	publisher = {ACM},
	author = {Peterson, James L.},
	month = sep,
	year = {1977},
	pages = {223--252},
}

@incollection{wang_petri_2007,
	edition = {1st},
	title = {Petri {Nets} for {Dynamic} {Event}-{Driven} {System} {Modeling}},
	booktitle = {Handbook of {Dynamic} {System} {Modeling}},
	publisher = {Chapman and Hall/CRC},
	author = {Wang, Jiacun},
	editor = {Fishwick, Paul A.},
	year = {2007},
	note = {Section: 24},
	pages = {1--18},
}

@incollection{brauer_carl_2009,
	title = {Carl {Adam} {Petri} and “{Petri} {Nets}”},
	url = {https://www.worldscientific.com/doi/10.1142/9781848162914\_0007},
	booktitle = {Fundamental {Concepts} in {Computer} {Science}},
	publisher = {World Scientific Publishing Co.},
	author = {Brauer, Wilfried and Reisig, Wolfgang},
	year = {2009},
	pages = {129--139},
}

@article{petri_fundamentals_1966,
	title = {Fundamentals on the description of discrete processes. 3rd {Colloq}},
	journal = {Autom. Theory},
	author = {Petri, Carl Adam},
	year = {1966},
}

@inproceedings{kalibatiene_survey_2011,
	title = {Survey on {Ontology} {Languages}},
	isbn = {978-3-642-24511-4},
	booktitle = {Perspectives in {Business} {Informatics} {Research}},
	publisher = {Springer Berlin Heidelberg},
	author = {Kalibatiene, Diana and Vasilecas, Olegas},
	editor = {Grabis, Janis and Kirikova, Marite},
	year = {2011},
	pages = {124--141},
}

@incollection{bienvenu_reasoning_2020,
	title = {Reasoning with {Ontologies}},
	isbn = {978-3-030-06164-7},
	url = {https://doi.org/10.1007/978-3-030-06164-7\_6},
	booktitle = {A {Guided} {Tour} of {Artificial} {Intelligence} {Research}: {Volume} {I}: {Knowledge} {Representation}, {Reasoning} and {Learning}},
	publisher = {Springer International Publishing},
	author = {Bienvenu, Meghyn and Leclère, Michel and Mugnier, Marie-Laure and Rousset, Marie-Christine},
	editor = {Marquis, Pierre and Papini, Odile and Prade, Henri},
	year = {2020},
	pages = {185--215},
}

@article{eilenberg_general_1945,
	title = {General theory of natural equivalences},
	volume = {58},
	url = {https://www.jstor.org/stable/1990284},
	number = {2},
	journal = {Transactions of the american mathematical society},
	author = {Eilenberg, Samuel and MacLane, Saunders},
	year = {1945},
	pages = {231--294},
}

@incollection{breiner_category_2023,
	title = {Category theory},
	booktitle = {Handbook of model-based systems engineering},
	publisher = {Springer},
	author = {Breiner, Spencer and Subrahmanian, Eswaran and Sriram, RD},
	year = {2023},
	pages = {1--41},
}

@article{motik_hypertableau_2009,
	title = {Hypertableau reasoning for description logics},
	volume = {36},
	journal = {Journal of Artificial Intelligence Research},
	author = {Motik, Boris and Shearer, Rob and Horrocks, Ian},
	year = {2009},
	pages = {165--228},
}

@book{baader_description_2003,
	title = {The description logic handbook: {Theory}, implementation and applications},
	publisher = {Cambridge university press},
	author = {Baader, Franz},
	year = {2003},
}

@article{horrocks_decidability_2004,
	title = {Decidability of {SHIQ} with complex role inclusion axioms},
	volume = {160},
	doi = {https://doi.org/10.1016/j.artint.2004.06.002},
	number = {1-2},
	journal = {Artificial Intelligence},
	publisher = {Elsevier},
	author = {Horrocks, Ian and Sattler, Ulrike},
	year = {2004},
	pages = {79--104},
}

@article{areces_resolution_2001,
	title = {Resolution in modal, description and hybrid logic},
	volume = {11},
	number = {5},
	journal = {Journal of Logic and Computation},
	publisher = {Oxford University Press},
	author = {Areces, Carlos and De Rijke, Maarten and De Nivelle, Hans},
	year = {2001},
	pages = {717--736},
}

@phdthesis{jaime_consequence-based_2019,
	type = {{PhD} {Thesis}},
	title = {Consequence-based reasoning for the {Description} {Logic} {SROIQ}},
	url = {https://ora.ox.ac.uk/objects/uuid:50e692ef-4ea6-4756-8b5c-7c84f95e0946},
	school = {University of Oxford},
	author = {Jaime, Tena Cucala David},
	year = {2019},
	annote = {PhD Thesis},
}

@inproceedings{ortiz_automata-based_2008,
	title = {An {Automata}-based algorithm for description logics around {SRIQ}.},
	url = {https://ceur-ws.org/Vol-408/Paper01.pdf},
	booktitle = {Proceedings of the fourth {Latin} {American} {Workshop} on {Non}-{Monotonic} {Reasoning} 2008 ({LANMR}'08)},
	author = {Ortiz, Magdalena},
	year = {2008},
}

@article{alviano_large-scale_2020,
	title = {Large-scale ontological reasoning via datalog},
	url = {https://ebooks.iospress.nl/volumearticle/56016},
	journal = {Applications and Practices in Ontology Design, Extraction, and Reasoning},
	publisher = {IOS Press},
	author = {Alviano, Mario and Manna, Marco},
	year = {2020},
	pages = {214--229},
}

@article{schmidt_automated_2011,
	title = {Automated synthesis of tableau calculi},
	volume = {7},
	url = {https://lmcs.episciences.org/970},
	journal = {Logical Methods in Computer Science},
	author = {Schmidt, Renate A and Tishkovsky, Dmitry},
	year = {2011},
}

@article{abraham_theory_2003,
	title = {From theory to data: {Representing} neurons in the 1940s},
	volume = {18},
	number = {3},
	journal = {Biology and Philosophy},
	publisher = {Springer},
	author = {Abraham, Tara H},
	year = {2003},
	pages = {415--426},
}

@article{mcculloch_logical_1943,
	title = {A logical calculus of the ideas immanent in nervous activity},
	volume = {5},
	number = {4},
	journal = {The bulletin of mathematical biophysics},
	publisher = {Springer},
	author = {McCulloch, Warren S and Pitts, Walter},
	year = {1943},
	pages = {115--133},
}

@article{page_prisma_2021,
	title = {The {PRISMA} 2020 statement: an updated guideline for reporting systematic reviews},
	volume = {372},
	journal = {bmj},
	publisher = {British Medical Journal Publishing Group},
	author = {Page, Matthew J and McKenzie, Joanne E and Bossuyt, Patrick M and Boutron, Isabelle and Hoffmann, Tammy C and Mulrow, Cynthia D and Shamseer, Larissa and Tetzlaff, Jennifer M and Akl, Elie A and Brennan, Sue E and {others}},
	year = {2021},
}

@article{nawaz_review_2025-1,
	title = {A review of neuro-symbolic {AI} integrating reasoning and learning for advanced cognitive systems},
	volume = {26},
	journal = {Intell. Syst. Appl.},
	author = {Nawaz, Uzma and Anees-ur-Rahaman, Mufti and Saeed, Zubair},
	year = {2025},
	pages = {200541},
}

@article{bhuyan_neuro-symbolic_2024-1,
	title = {Neuro-symbolic artificial intelligence: a survey},
	volume = {36},
	number = {21},
	journal = {Neural Comput. Appl.},
	author = {Bhuyan, Bikram Pratim and Ramdane-Cherif, Amar and Tomar, Ravi and Singh, T. P.},
	year = {2024},
	pages = {12809--12844},
}

@article{lu_surveying_2024-1,
	title = {Surveying neuro-symbolic approaches for reliable artificial intelligence of things},
	volume = {10},
	number = {3},
	journal = {J. Reliab. Intell. Environ.},
	author = {Lu, Zhen and Afridi, Imran and Kang, Hong Jin and Ruchkin, Ivan and Zheng, Xi},
	year = {2024},
	pages = {257--279},
}

@article{moffaert_multi-objective_2014,
	title = {Multi-objective reinforcement learning using sets of pareto dominating policies},
	volume = {15},
	number = {1},
	journal = {J. Mach. Learn. Res.},
	author = {Moffaert, Kristof Van and Nowé, Ann},
	year = {2014},
	pages = {3483--3512},
}

@inproceedings{xu_prediction-guided_2020-1,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Prediction-{Guided} {Multi}-{Objective} {Reinforcement} {Learning} for {Continuous} {Robot} {Control}},
	volume = {119},
	booktitle = {{ICML}},
	publisher = {PMLR},
	author = {Xu, Jie and Tian, Yunsheng and Ma, Pingchuan and Rus, Daniela and Sueda, Shinjiro and Matusik, Wojciech},
	year = {2020},
	pages = {10607--10616},
}

@article{wang_voyager_2024,
	title = {Voyager: {An} {Open}-{Ended} {Embodied} {Agent} with {Large} {Language} {Models}},
	volume = {2024},
	journal = {Trans. Mach. Learn. Res.},
	author = {Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
	year = {2024},
}

@article{felten_multi-objective_2024-1,
	title = {Multi-{Objective} {Reinforcement} {Learning} {Based} on {Decomposition}: {A} {Taxonomy} and {Framework}},
	volume = {79},
	journal = {J. Artif. Intell. Res.},
	author = {Felten, Florian and Talbi, El-Ghazali and Danoy, Grégoire},
	year = {2024},
	pages = {679--723},
}

@article{hsiao_neural_2002-1,
	title = {A neural network based approach for product form design},
	volume = {23},
	issn = {0142-694X},
	number = {1},
	journal = {Design Studies},
	author = {Hsiao, Shih-Wen and Huang, H. C},
	year = {2002},
	pages = {67--84},
}

@article{bodendorf_artificial_2022,
	title = {Artificial neural networks for intelligent cost estimation - a contribution to strategic cost management in the manufacturing supply chain},
	volume = {60},
	number = {21},
	journal = {Int. J. Prod. Res.},
	author = {Bodendorf, Frank and Merkl, Philipp and Franke, Jörg},
	year = {2022},
	pages = {6637--6658},
}

@article{dash_review_2022-1,
	title = {A review of some techniques for inclusion of domain-knowledge into deep neural networks},
	volume = {12},
	issn = {2045-2322},
	number = {1},
	journal = {Sci Rep},
	author = {Dash, Tirtharaj and Chitlangia, Sharad and Ahuja, Aditya and Srinivasan, Ashwin},
	year = {2022},
	pages = {1040},
	annote = {Publisher: Nature Publishing Group},
}

@article{xie_graph_2022-1,
	title = {Graph neural network-enabled manufacturing method classification from engineering drawings},
	volume = {142},
	journal = {Comput. Ind.},
	author = {Xie, Liuyue and Lu, Yao and Furuhata, Tomotake and Yamakawa, Soji and Zhang, Wentai and Regmi, Amit and Kara, Levent Burak and Shimada, Kenji},
	year = {2022},
	pages = {103697},
}

@inproceedings{garcez_neural-symbolic_2015,
	title = {Neural-{Symbolic} {Learning} and {Reasoning}: {Contributions} and {Challenges}.},
	booktitle = {{AAAI} {Spring} {Symposia}},
	author = {Garcez, Artur S d'Avila and Besold, Tarek R and De Raedt, Luc and Földiak, Peter and Hitzler, Pascal and Icard, Thomas and Kühnberger, Kai-Uwe and Lamb, Luis C and Miikkulainen, Risto and Silver, Daniel L},
	year = {2015},
	pages = {18--21},
}

@article{franca_fast_2014-1,
	title = {Fast relational learning using bottom clause propositionalization with artificial neural networks},
	volume = {94},
	number = {1},
	journal = {Mach. Learn.},
	author = {França, Manoel V. M. and Zaverucha, Gerson and Garcez, Artur S. d'Avila},
	year = {2014},
	pages = {81--104},
}

@article{mitchener_detect_2022-1,
	title = {Detect, {Understand}, {Act}: {A} {Neuro}-symbolic {Hierarchical} {Reinforcement} {Learning} {Framework}},
	volume = {111},
	number = {4},
	journal = {Mach. Learn.},
	author = {Mitchener, Ludovico and Tuckey, David and Crosby, Matthew and Russo, Alessandra},
	year = {2022},
}

@inproceedings{anderson_neurosymbolic_2020-1,
	title = {Neurosymbolic {Reinforcement} {Learning} with {Formally} {Verified} {Exploration}},
	booktitle = {{NeurIPS}},
	author = {Anderson, Greg and Verma, Abhinav and Dillig, Isil and Chaudhuri, Swarat},
	year = {2020},
}

@inproceedings{dellermann_future_2019,
	title = {The {Future} of {Human}-{AI} {Collaboration}: {A} {Taxonomy} of {Design} {Knowledge} for {Hybrid} {Intelligence} {Systems}},
	booktitle = {{HICSS}},
	publisher = {ScholarSpace},
	author = {Dellermann, Dominik and Calma, Adrian and Lipusch, Nikolaus and Weber, Thorsten and Weigel, Sascha and Ebel, Philipp},
	year = {2019},
	pages = {1--10},
}

@article{yong_product_2024,
	title = {Product perceptual design optimization model based on {BP} neural network},
	volume = {Volume 10 - 2024},
	issn = {2297-3079},
	journal = {Frontiers in Mechanical Engineering},
	author = {Yong, Lei},
	year = {2024},
}

@inproceedings{bordes_translating_2013-1,
	title = {Translating {Embeddings} for {Modeling} {Multi}-relational {Data}},
	booktitle = {{NIPS}},
	author = {Bordes, Antoine and Usunier, Nicolas and García-Durán, Alberto and Weston, Jason and Yakhnenko, Oksana},
	year = {2013},
	pages = {2787--2795},
}

@article{ratner_snorkel_2020,
	title = {Snorkel: rapid training data creation with weak supervision},
	volume = {29},
	number = {2-3},
	journal = {VLDB J.},
	author = {Ratner, Alexander and Bach, Stephen H. and Ehrenberg, Henry R. and Fries, Jason A. and Wu, Sen and Ré, Christopher},
	year = {2020},
	pages = {709--730},
}

@article{silver_mastering_2017,
	title = {Mastering the game of {Go} without human knowledge},
	volume = {550},
	number = {7676},
	journal = {Nat.},
	author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy P. and Hui, Fan and Sifre, Laurent and Driessche, George van den and Graepel, Thore and Hassabis, Demis},
	year = {2017},
	pages = {354--359},
}

@inproceedings{mao_neuro-symbolic_2019,
	title = {The {Neuro}-{Symbolic} {Concept} {Learner}: {Interpreting} {Scenes}, {Words}, and {Sentences} {From} {Natural} {Supervision}},
	booktitle = {{ICLR}},
	publisher = {OpenReview.net},
	author = {Mao, Jiayuan and Gan, Chuang and Kohli, Pushmeet and Tenenbaum, Joshua B. and Wu, Jiajun},
	year = {2019},
}

@inproceedings{marino_krisp_2021-1,
	title = {{KRISP}: {Integrating} {Implicit} and {Symbolic} {Knowledge} for {Open}-{Domain} {Knowledge}-{Based} {VQA}},
	booktitle = {{CVPR}},
	publisher = {Computer Vision Foundation / IEEE},
	author = {Marino, Kenneth and Chen, Xinlei and Parikh, Devi and Gupta, Abhinav and Rohrbach, Marcus},
	year = {2021},
	pages = {14111--14121},
}

@inproceedings{xu_semantic_2018-1,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {A {Semantic} {Loss} {Function} for {Deep} {Learning} with {Symbolic} {Knowledge}},
	volume = {80},
	booktitle = {{ICML}},
	publisher = {PMLR},
	author = {Xu, Jingyi and Zhang, Zilu and Friedman, Tal and Liang, Yitao and Broeck, Guy Van den},
	year = {2018},
	pages = {5498--5507},
}

@inproceedings{kaliszyk_holstep_2017-1,
	title = {{HolStep}: {A} {Machine} {Learning} {Dataset} for {Higher}-order {Logic} {Theorem} {Proving}},
	booktitle = {{ICLR} ({Poster})},
	publisher = {OpenReview.net},
	author = {Kaliszyk, Cezary and Chollet, François and Szegedy, Christian},
	year = {2017},
}

@article{renkhoff_survey_2024,
	title = {A {Survey} on {Verification} and {Validation}, {Testing} and {Evaluations} of {Neurosymbolic} {Artificial} {Intelligence}},
	volume = {5},
	number = {8},
	journal = {IEEE Trans. Artif. Intell.},
	author = {Renkhoff, Justus and Feng, Ke and Meier-Doernberg, Marc and Velasquez, Alvaro and Song, Houbing Herbert},
	year = {2024},
	pages = {3765--3779},
}

@article{wollstadt_carhoods10k_2022,
	title = {{CarHoods10k}: {An} {Industry}-{Grade} {Data} {Set} for {Representation} {Learning} and {Design} {Optimization} in {Engineering} {Applications}},
	volume = {26},
	number = {6},
	journal = {IEEE Trans. Evol. Comput.},
	author = {Wollstadt, Patricia and Bujny, Mariusz and Ramnath, Satchit and Shah, Jami J. and Detwiler, Duane and Menzel, Stefan},
	year = {2022},
	pages = {1221--1235},
}

@inproceedings{xu_hierarchical_2023,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Hierarchical {Neural} {Coding} for {Controllable} {CAD} {Model} {Generation}},
	volume = {202},
	booktitle = {{ICML}},
	publisher = {PMLR},
	author = {Xu, Xiang and Jayaraman, Pradeep Kumar and Lambourne, Joseph George and Willis, Karl D. D. and Furukawa, Yasutaka},
	year = {2023},
	pages = {38443--38461},
}

@article{ritchie_neurosymbolic_2023,
	title = {Neurosymbolic {Models} for {Computer} {Graphics}},
	volume = {42},
	number = {2},
	journal = {Comput. Graph. Forum},
	author = {Ritchie, Daniel and Guerrero, Paul and Jones, R. Kenny and Mitra, Niloy J. and Schulz, Adriana and Willis, Karl D. D. and Wu, Jiajun},
	year = {2023},
	pages = {545--568},
}

@article{hao_integrating_2021,
	title = {Integrating and navigating engineering design decision-related knowledge using decision knowledge graph},
	volume = {50},
	journal = {Adv. Eng. Informatics},
	author = {Hao, Jia and Zhao, Lei and Milisavljevic-Syed, Jelena and Ming, Z.},
	year = {2021},
	pages = {101366},
}

@article{boer_design_2025,
	title = {Design {Patterns} for {Large} {Language} {Model} {Based} {Neuro}-{Symbolic} {Systems}},
	volume = {1},
	journal = {Neurosymbolic Artificial Intelligence},
	author = {Boer, Maaike de and Smit, Quirine and Bekkum, Michael van and Meyer-Vitali, André and Schmid, Thomas},
	year = {2025},
	pages = {29498732251377499},
}

@article{niu_pht-cad_2025,
	title = {{PHT}-{CAD}: {Efficient} {CAD} {Parametric} {Primitive} {Analysis} with {Progressive} {Hierarchical} {Tuning}},
	volume = {abs/2503.18147},
	journal = {CoRR},
	author = {Niu, Ke and Chen, Yuwen and Yu, Haiyang and Chen, Zhuofan and Que, Xianghui and Li, Bin and Xue, Xiangyang},
	year = {2025},
}

@article{chai_circuitnet_2023,
	title = {{CircuitNet}: {An} {Open}-{Source} {Dataset} for {Machine} {Learning} in {VLSI} {CAD} {Applications} {With} {Improved} {Domain}-{Specific} {Evaluation} {Metric} and {Learning} {Strategies}},
	volume = {42},
	number = {12},
	journal = {IEEE Trans. Comput. Aided Des. Integr. Circuits Syst.},
	author = {Chai, Zhuomin and Zhao, Yuxiang and Liu, Wei and Lin, Yibo and Wang, Runsheng and Huang, Ru},
	year = {2023},
	pages = {5034--5047},
}

@article{luo_archcad-400k_2025,
	title = {{ArchCAD}-{400K}: {An} {Open} {Large}-{Scale} {Architectural} {CAD} {Dataset} and {New} {Baseline} for {Panoptic} {Symbol} {Spotting}},
	volume = {abs/2503.22346},
	journal = {CoRR},
	author = {Luo, Ruifeng and Liu, Zhengjie and Cheng, Tianxiao and Wang, Jie and Wang, Tongjie and Wei, Xingguang and Wang, Haomin and Li, Yanpeng and Chai, Fu and Cheng, Fei and Ye, Shenglong and Wang, Wenhai and Zhang, Yanting and Qiao, Yu and Zhang, Hongjie and Zhao, Xianzhong},
	year = {2025},
}

@inproceedings{collins_abo_2022,
	title = {{ABO}: {Dataset} and {Benchmarks} for {Real}-{World} {3D} {Object} {Understanding}},
	booktitle = {{CVPR}},
	publisher = {IEEE},
	author = {Collins, Jasmine and Goel, Shubham and Deng, Kenan and Luthra, Achleshwar and Xu, Leon and Gundogdu, Erhan and Zhang, Xi and Vicente, Tomas F. Yago and Dideriksen, Thomas and Arora, Himanshu and Guillaumin, Matthieu and Malik, Jitendra},
	year = {2022},
	pages = {21094--21104},
}

@article{choudhary_jarvis-leaderboard_2024,
	title = {{JARVIS}-{Leaderboard}: a large scale benchmark of materials design methods},
	volume = {10},
	number = {1},
	journal = {npj Computational Materials},
	publisher = {Nature Publishing Group UK London},
	author = {Choudhary, Kamal and Wines, Daniel and Li, Kangming and Garrity, Kevin F and Gupta, Vishu and Romero, Aldo H and Krogel, Jaron T and Saritas, Kayahan and Fuhr, Addis and Ganesh, Panchapakesan and {others}},
	year = {2024},
	pages = {93},
}

@article{baird_materials_2023,
	title = {Materials science optimization benchmark dataset for multi-objective, multi-fidelity optimization of hard-sphere packing simulations},
	volume = {50},
	journal = {Data in Brief},
	publisher = {Elsevier},
	author = {Baird, Sterling G and Issa, Ramsey and Sparks, Taylor D},
	year = {2023},
	pages = {109487},
}

@article{lehrer_ucsm_2025,
	title = {{UCSM}: {Dataset} of {U}-shaped parametric {CAD} geometries and real-world sheet metal meshes for deep drawing},
	volume = {188},
	issn = {0010-4485},
	journal = {Computer-Aided Design},
	author = {Lehrer, Tobias and Stocker, Philipp and Duddeck, Fabian and Wagner, Marcus},
	year = {2025},
	pages = {103924},
}

@article{marcus_next_2020,
	title = {The {Next} {Decade} in {AI}: {Four} {Steps} {Towards} {Robust} {Artificial} {Intelligence}},
	volume = {abs/2002.06177},
	journal = {CoRR},
	author = {Marcus, Gary},
	year = {2020},
}

@article{you_img2cad_2024,
	title = {{Img2CAD}: {Reverse} {Engineering} {3D} {CAD} {Models} from {Images} through {VLM}-{Assisted} {Conditional} {Factorization}},
	volume = {abs/2408.01437},
	journal = {CoRR},
	author = {You, Yang and Uy, Mikaela Angelina and Han, Jiaqi and Thomas, Rahul Krishna and Zhang, Haotong and You, Suya and Guibas, Leonidas J.},
	year = {2024},
}

@inproceedings{vaswani_attention_2017,
	title = {Attention is {All} you {Need}},
	booktitle = {{NIPS}},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	year = {2017},
	pages = {5998--6008},
}

@article{picard_concept_2025,
	title = {From concept to manufacturing: evaluating vision-language models for engineering design},
	volume = {58},
	number = {9},
	journal = {Artif. Intell. Rev.},
	author = {Picard, Cyril and Edwards, Kristen M. and Doris, Anna C. and Man, Brandon and Giannone, Giorgio and Alam, Md Ferdous and Ahmed, Faez},
	year = {2025},
	pages = {288},
}

@inproceedings{wu_cadvlm_2024,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{CadVLM}: {Bridging} {Language} and {Vision} in the {Generation} of {Parametric} {CAD} {Sketches}},
	volume = {15128},
	booktitle = {{ECCV} (70)},
	publisher = {Springer},
	author = {Wu, Sifan and Khasahmadi, Amir Hosein and Katz, Mor and Jayaraman, Pradeep Kumar and Pu, Yewen and Willis, Karl D. D. and Liu, Bang},
	year = {2024},
	pages = {368--384},
}

@inproceedings{finn_model-agnostic_2017,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Model-{Agnostic} {Meta}-{Learning} for {Fast} {Adaptation} of {Deep} {Networks}},
	volume = {70},
	booktitle = {{ICML}},
	publisher = {PMLR},
	author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
	year = {2017},
	pages = {1126--1135},
}

@article{zajec_few-shot_2024,
	title = {Few-shot learning for defect detection in manufacturing},
	volume = {62},
	number = {19},
	journal = {Int. J. Prod. Res.},
	author = {Zajec, Patrik and Rozanec, Joze M. and Theodoropoulos, Spyros and Fontul, Mihail and Koehorst, Erik and Fortuna, Blaz and Mladenic, Dunja},
	year = {2024},
	pages = {6979--6998},
}

@article{kuszczak_meta-neural_2025,
	title = {Meta-neural {Topology} {Optimization}: {Knowledge} {Infusion} with {Meta}-learning},
	volume = {abs/2502.01830},
	journal = {CoRR},
	author = {Kuszczak, Igor and Kus, Gawel I. and Bosi, Federico and Bessa, Miguel A.},
	year = {2025},
}

@article{zhang_ecad-net_2025,
	title = {{eCAD}-{Net}: {Editable} {Parametric} {CAD} {Models} {Reconstruction} from {Dumb} {B}-{Rep} {Models} {Using} {Deep} {Neural} {Networks}},
	volume = {178},
	journal = {Comput. Aided Des.},
	author = {Zhang, Chao and Polette, Arnaud and Pinquié, Romain and Carasi, Gregorio and Charnace, Henri De and Pernot, Jean-Philippe},
	year = {2025},
	pages = {103806},
}

@article{haq_multimodal_2024,
	title = {Multimodal {Neurosymbolic} {Approach} for {Explainable} {Deepfake} {Detection}},
	volume = {20},
	number = {11},
	journal = {ACM Trans. Multim. Comput. Commun. Appl.},
	author = {Haq, Ijaz Ul and Malik, Khalid Mahmood and Muhammad, Khan},
	year = {2024},
	pages = {341:1--341:16},
}

@inproceedings{sanders_tv-trees_2024,
	title = {{TV}-{TREES}: {Multimodal} {Entailment} {Trees} for {Neuro}-{Symbolic} {Video} {Reasoning}},
	booktitle = {{EMNLP}},
	publisher = {Association for Computational Linguistics},
	author = {Sanders, Kate and Weir, Nathaniel and Durme, Benjamin Van},
	year = {2024},
	pages = {19009--19028},
}

@inproceedings{yang_neuro-symbolic_2025,
	title = {Neuro-{Symbolic} {Artificial} {Intelligence}: {Towards} {Improving} the {Reasoning} {Abilities} of {Large} {Language} {Models}},
	booktitle = {{IJCAI}},
	publisher = {ijcai.org},
	author = {Yang, Xiao-Wen and Shao, Jie-Jing and Guo, Lan-Zhe and Zhang, Bo-Wen and Zhou, Zhi and Jia, Lin-Han and Dai, Wang-Zhou and Li, Yufeng},
	year = {2025},
	pages = {10770--10778},
}

@article{xu_adaptive_2025,
	title = {Adaptive {LLM}-{Symbolic} {Reasoning} via {Dynamic} {Logical} {Solver} {Composition}},
	journal = {arXiv preprint arXiv:2510.06774},
	author = {Xu, Lei and Beckmann, Pierre and Valentino, Marco and Freitas, André},
	year = {2025},
}

@article{saha_tinyns_2024,
	title = {{TinyNS}: {Platform}-aware {Neurosymbolic} {Auto} {Tiny} {Machine} {Learning}},
	volume = {23},
	number = {3},
	journal = {ACM Trans. Embed. Comput. Syst.},
	author = {Saha, Swapnil Sayan and Sandha, Sandeep Singh and Aggarwal, Mohit and Wang, Brian and Han, Liying and Briseno, Julian de Gortari and Srivastava, Mani},
	year = {2024},
	pages = {43:1--43:48},
}

@article{biberstein_lobster_2025,
	title = {Lobster: {A} {GPU}-{Accelerated} {Framework} for {Neurosymbolic} {Programming}},
	journal = {arXiv preprint arXiv:2503.21937},
	author = {Biberstein, Paul and Li, Ziyang and Devietti, Joseph and Naik, Mayur},
	year = {2025},
}

@article{wan_towards_2024,
	title = {Towards {Efficient} {Neuro}-{Symbolic} {AI}: {From} {Workload} {Characterization} to {Hardware} {Architecture}},
	volume = {abs/2409.13153},
	journal = {CoRR},
	author = {Wan, Zishen and Liu, Che-Kai and Yang, Hanchen and Raj, Ritik and Li, Chaojian and You, Haoran and Fu, Yonggan and Wan, Cheng and Li, Sixu and Kim, Youbin and Samajdar, Ananda and Lin, Yingyan Celine and Ibrahim, Mohamed and Rabaey, Jan M. and Krishna, Tushar and Raychowdhury, Arijit},
	year = {2024},
}

@inproceedings{wan_cogsys_2025,
	title = {{CogSys}: {Efficient} and {Scalable} {Neurosymbolic} {Cognition} {System} via {Algorithm}-{Hardware} {Co}-{Design}},
	booktitle = {{HPCA}},
	publisher = {IEEE},
	author = {Wan, Zishen and Yang, Hanchen and Raj, Ritik and Liu, Che-Kai and Samajdar, Ananda and Raychowdhury, Arijit and Krishna, Tushar},
	year = {2025},
	pages = {775--789},
}

@article{pan_logic-lm_2023,
	title = {Logic-{LM}: {Empowering} {Large} {Language} {Models} with {Symbolic} {Solvers} for {Faithful} {Logical} {Reasoning}},
	volume = {abs/2305.12295},
	journal = {CoRR},
	author = {Pan, Liangming and Albalak, Alon and Wang, Xinyi and Wang, William Yang},
	year = {2023},
}

@article{hagos_neuro-symbolic_2024,
	title = {Neuro-{Symbolic} {AI} for {Military} {Applications}},
	volume = {5},
	number = {12},
	journal = {IEEE Trans. Artif. Intell.},
	author = {Hagos, Desta Haileselassie and Rawat, Danda B.},
	year = {2024},
	pages = {6012--6026},
}

@article{novelli_accountability_2024,
	title = {Accountability in artificial intelligence: what it is and how it works},
	volume = {39},
	number = {4},
	journal = {AI Soc.},
	author = {Novelli, Claudio and Taddeo, Mariarosaria and Floridi, Luciano},
	year = {2024},
	pages = {1871--1882},
}

@article{alvarez_policy_2024,
	title = {Policy advice and best practices on bias and fairness in {AI}},
	volume = {26},
	number = {2},
	journal = {Ethics and Information Technology},
	publisher = {Springer},
	author = {Alvarez, Jose M and Colmenarejo, Alejandra Bringas and Elobaid, Alaa and Fabbrizzi, Simone and Fahimi, Miriam and Ferrara, Antonio and Ghodsi, Siamak and {others}},
	year = {2024},
	pages = {31},
}

@article{ntoutsi_bias_2020,
	title = {Bias in data-driven artificial intelligence systems—{An} introductory survey},
	volume = {10},
	number = {3},
	journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
	publisher = {Wiley Online Library},
	author = {Ntoutsi, Eirini and Fafalios, Pavlos and Gadiraju, Ujwal and Iosifidis, Vasileios and Nejdl, Wolfgang and Vidal, Maria-Esther and Ruggieri, Salvatore and {others}},
	year = {2020},
	pages = {e1356},
}

@article{kohaut_probabilistic_2025,
	title = {Probabilistic {Mission} {Design} for {Neuro}-{Symbolic} {Unmanned} {Aircraft} {Systems}},
	volume = {26},
	number = {12},
	journal = {IEEE Trans. on Intell. Transport. Sys.},
	author = {Kohaut, Simon and Flade, Benedict and Ochs, Daniel and {Dhami} and {others}},
	year = {2025},
	pages = {22751--22760},
}

@article{garcez_neurosymbolic_2023-1,
	title = {Neurosymbolic {AI}: the 3rd wave},
	volume = {56},
	number = {11},
	journal = {Artif. Intell. Rev.},
	author = {Garcez, Artur d'Avila and Lamb, Luís C.},
	year = {2023},
	pages = {12387--12406},
}

@article{yu_survey_2023-1,
	title = {A survey on neural-symbolic learning systems},
	volume = {166},
	journal = {Neural Networks},
	author = {Yu, Dongran and Yang, Bo and Liu, Dayou and Wang, Hui and Pan, Shirui},
	year = {2023},
	pages = {105--126},
}

@article{manhaeve_neural_2021-1,
	title = {Neural probabilistic logic programming in {DeepProbLog}},
	volume = {298},
	journal = {Artif. Intell.},
	author = {Manhaeve, Robin and Dumancic, Sebastijan and Kimmig, Angelika and Demeester, Thomas and Raedt, Luc De},
	year = {2021},
	pages = {103504},
}

@article{roijers_survey_2013-1,
	title = {A {Survey} of {Multi}-{Objective} {Sequential} {Decision}-{Making}},
	volume = {48},
	journal = {J. Artif. Intell. Res.},
	author = {Roijers, Diederik M. and Vamplew, Peter and Whiteson, Shimon and Dazeley, Richard},
	year = {2013},
	pages = {67--113},
}

@book{staab_handbook_2004,
	series = {International {Handbooks} on {Information} {Systems}},
	title = {Handbook on {Ontologies}},
	publisher = {Springer},
	editor = {Staab, Steffen and Studer, Rudi},
	year = {2004},
}

@incollection{besold_neural-symbolic_2021,
	title = {Neural-symbolic learning and reasoning: {A} survey and interpretation},
	booktitle = {Neuro-symbolic artificial intelligence: {The} state of the art},
	publisher = {IOS press},
	author = {Besold, Tarek R and Bader, Sebastian and Bowman, Howard and Domingos, Pedro and {Hitzler} and {others}},
	year = {2021},
	pages = {1--51},
}

@article{hayes_practical_2021,
	title = {A practical guide to multi-objective reinforcement learning and planning},
	journal = {arXiv preprint arXiv:2103.09568},
	author = {Hayes, Conor F and Rădulescu, Roxana and Bargiacchi, Eugenio and Källström, Johan and Macfarlane, Matthew and Reymond, Mathieu and {Verstraeten} and {others}},
	year = {2021},
}

@article{acharya_neurosymbolic_2024-1,
	title = {Neurosymbolic {Reinforcement} {Learning} and {Planning}: {A} {Survey}},
	volume = {5},
	number = {5},
	journal = {IEEE Trans. Artif. Intell.},
	author = {Acharya, Kamal and Raza, Waleed and Júnior, Carlos M. J. M. Dourado and Velasquez, Alvaro and Song, Houbing Herbert},
	year = {2024},
	pages = {1939--1953},
}

@article{kim_ontology-based_2006,
	title = {Ontology-based assembly design and information sharing for collaborative product development},
	volume = {38},
	number = {12},
	journal = {Comput. Aided Des.},
	author = {Kim, Kyoung-Yun and Manley, David G. and Yang, Hyung Jeong},
	year = {2006},
	pages = {1233--1250},
}

@inproceedings{terziyan_taxonomy-informed_2024-1,
	series = {Procedia {Computer} {Science}},
	title = {Taxonomy-{Informed} {Neural} {Networks} for {Smart} {Manufacturing}},
	volume = {232},
	booktitle = {{ISM}},
	publisher = {Elsevier},
	author = {Terziyan, Vagan Y. and Vitko, Oleksandra},
	year = {2024},
	pages = {1388--1399},
}

@article{graf_three_2024-1,
	title = {Three {Pathways} to {Neurosymbolic} {Reinforcement} {Learning} with {Interpretable} {Model} and {Policy} {Networks}},
	volume = {abs/2402.05307},
	journal = {CoRR},
	author = {Graf, Peter and Emami, Patrick},
	year = {2024},
}

@article{rosell_assembly_2004,
	title = {Assembly and task planning using {Petri} nets: a survey},
	volume = {218},
	number = {8},
	journal = {Proceedings of the institution of mechanical engineers, part B: journal of engineering manufacture},
	publisher = {Sage Publications Sage UK: London, England},
	author = {Rosell, Jan},
	year = {2004},
	pages = {987--994},
}

@article{golpayegani_advancing_2024-1,
	title = {Advancing {Sustainable} {Manufacturing}: {Reinforcement} {Learning} with {Adaptive} {Reward} {Machine} {Using} an {Ontology}-{Based} {Approach}},
	volume = {16},
	number = {14},
	journal = {Sustainability},
	publisher = {MDPI},
	author = {Golpayegani, Fatemeh and Ghanadbashi, Saeedeh and Zarchini, Akram},
	year = {2024},
	pages = {5873},
}

@incollection{nardi_introduction_2007,
	title = {An introduction to description logics.},
	booktitle = {Descr. logic handbook},
	publisher = {Cambridge Uni Press},
	author = {Nardi, Daniele and Brachman, Ronald J},
	year = {2007},
	pages = {1--44},
}

@article{yuan_openecad_2024-1,
	title = {{OpenECAD}: {An} efficient visual language model for editable {3D}-{CAD} design},
	volume = {124},
	journal = {Comp. Graph.},
	author = {Yuan, Zhe and Shi, Jianqi and Huang, Yanhong},
	year = {2024},
	pages = {104048},
}

@article{li_llm4cad_2025,
	title = {{LLM4CAD}: {Multimodal} {Large} {Language} {Models} for {Three}-{Dimensional} {Computer}-{Aided} {Design} {Generation}},
	volume = {25},
	number = {1},
	journal = {J. Comput. Inf. Sci. Eng.},
	author = {Li, Xingang and Sun, Yuewan and Sha, Zhenghui},
	year = {2025},
}

@article{wang_mcgan_2025-1,
	title = {{McGAN}: {Generating} manufacturable designs by embedding manufacturing rules into conditional generative adversarial network},
	volume = {64},
	journal = {Adv. Eng. Informatics},
	author = {Wang, Zhichao and Yan, Xiaoliang and Melkote, Shreyes N. and Rosen, David},
	year = {2025},
	pages = {103074},
}

@article{huang_material_2024-1,
	title = {Material {Property} {Prediction} with {Element} {Attribute} {Knowledge} {Graphs} and {Multimodal} {Representation} {Learning}},
	volume = {abs/2411.08414},
	journal = {CoRR},
	author = {Huang, Chao and Chen, Chunyan and Shi, Ling and Chen, Chen},
	year = {2024},
}

@article{maciol_new_2025-1,
	title = {A new ontology-based approach to automatic information extraction from speech for production disturbance management},
	volume = {136},
	number = {7},
	journal = {The Inter. J. Adv. Manufact. Tech.},
	publisher = {Springer},
	author = {Macioł, Andrzej and Macioł, Piotr and Gumienny, Grzegorz and Wrzała, Konrad},
	year = {2025},
	pages = {3735--3752},
}

@article{yang_ontology-based_2023-1,
	title = {Ontology-based knowledge representation of industrial production workflow},
	volume = {58},
	journal = {Adv. Eng. Inform.},
	author = {Yang, Chao and Zheng, Yuan and Tu, Xinyi and {others}},
	year = {2023},
	pages = {102185},
}

@inproceedings{yan_periodic_2022-1,
	title = {Periodic {Graph} {Transformers} for {Crystal} {Material} {Property} {Prediction}},
	booktitle = {{NeurIPS}},
	author = {Yan, Keqiang and Liu, Yi and Lin, Yuchao and Ji, Shuiwang},
	year = {2022},
}

@inproceedings{tian_asap_2024-1,
	title = {{ASAP}: {Automated} {Sequence} {Planning} for {Complex} {Robotic} {Assembly} with {Physical} {Feasibility}},
	booktitle = {{ICRA}},
	publisher = {IEEE},
	author = {Tian, Yunsheng and Willis, Karl D. D. and Omari, Bassel Al and Luo, Jieliang and {others}},
	year = {2024},
	pages = {4380--4386},
}

@inproceedings{carr_safe_2023,
	title = {Safe {Reinforcement} {Learning} via {Shielding} under {Partial} {Observability}},
	booktitle = {{AAAI}},
	publisher = {AAAI Press},
	author = {Carr, Steven and Jansen, Nils and Junges, Sebastian and Topcu, Ufuk},
	year = {2023},
	pages = {14748--14756},
}

@article{odriozola-olalde_towards_2025-1,
	title = {Towards robust shielded reinforcement learning through adaptive constraints and exploration: {The} fear field framework},
	volume = {144},
	journal = {Eng. App. Artif. Intell.},
	author = {Odriozola-Olalde, Haritz and Zamalloa, Maider and {others}},
	year = {2025},
	pages = {110055},
}

@article{dong_neurcadrecon_2024-1,
	title = {{NeurCADRecon}: {Neural} {Representation} for {Reconstructing} {CAD} {Surfaces} by {Enforcing} {Zero} {Gaussian} {Curvature}},
	volume = {43},
	number = {4},
	journal = {ACM Trans. Graph.},
	author = {Dong, Qiujie and Xu, Rui and Wang, Pengfei and {others}},
	year = {2024},
	pages = {51:1--51:17},
}

@inproceedings{berzins_geometry-informed_2025-1,
	title = {Geometry-{Informed} {Neural} {Networks}},
	booktitle = {{ICML}},
	publisher = {OpenReview.net},
	author = {Berzins, Arturs and Radler, Andreas and Volkmann, Eric and {others}},
	year = {2025},
}

@article{jeong_complete_2023-1,
	title = {A {Complete} {Physics}-{Informed} {Neural} {Network}-{Based} {Framework} for {Structural} {Topology} {Optimization}},
	volume = {417},
	journal = {Comput. Methods Appl. Mech. Eng.},
	author = {Jeong, Hyogu and Batuwatta-Gamage, Chanaka and Bai, Jinshuai and Xie, Yi Min and {others}},
	year = {2023},
	pages = {116401},
}

@inproceedings{amos_optnet_2017-1,
	title = {{OptNet}: {Differentiable} {Optimization} as a {Layer} in {Neural} {Networks}},
	booktitle = {{ICML}},
	publisher = {PMLR},
	author = {Amos, Brandon and Kolter, J. Zico},
	year = {2017},
	pages = {136--145},
}

@inproceedings{agrawal_differentiable_2019-1,
	title = {Differentiable {Convex} {Optimization} {Layers}},
	booktitle = {{NeurIPS}},
	author = {Agrawal, Akshay and Amos, Brandon and Barratt, Shane T. and Boyd, Stephen P. and Diamond, Steven and Kolter, J. Zico},
	year = {2019},
	pages = {9558--9570},
}

@article{prasad_nurbs-diff_2022,
	title = {{NURBS}-{Diff}: {A} {Differentiable} {Programming} {Module} for {NURBS}},
	volume = {146},
	journal = {Comput. Aided Des.},
	author = {Prasad, Anjana Deva and Balu, Aditya and Shah, Harshil and Sarkar, Soumik and {others}},
	year = {2022},
	pages = {103199},
}

@article{wu_nesygeo_2025-1,
	title = {{NeSyGeo}: {A} {Neuro}-{Symbolic} {Framework} for {Multimodal} {Geometric} {Reasoning} {Data} {Generation}},
	volume = {abs/2505.17121},
	journal = {CoRR},
	author = {Wu, Weiming and Wang, Zi-kang and Ye, Jin and Zhou, Zhi and Li, Yufeng and Guo, Lan-Zhe},
	year = {2025},
}

@inproceedings{luo_end--end_2024-1,
	title = {End-to-{End} {Neuro}-{Symbolic} {Reinforcement} {Learning} with {Textual} {Explanations}},
	booktitle = {{ICML}},
	publisher = {OpenReview.net},
	author = {Luo, Lirui and Zhang, Guoxi and Xu, Hongming and Yang, Yaodong and Fang, Cong and Li, Qing},
	year = {2024},
}

@inproceedings{jacobson_integrating_2025-1,
	title = {Integrating {Symbolic} {Reasoning} into {Neural} {Generative} {Models} for {Design} {Generation}},
	booktitle = {{AAAI}},
	publisher = {AAAI Press},
	author = {Jacobson, Maxwell J. and Xue, Yexiang},
	year = {2025},
	pages = {28741},
}

@inproceedings{fischer_dl2_2019-1,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {{DL2}: {Training} and {Querying} {Neural} {Networks} with {Logic}},
	volume = {97},
	booktitle = {{ICML}},
	publisher = {PMLR},
	author = {Fischer, Marc and Balunovic, Mislav and Drachsler-Cohen, Dana and Gehr, Timon and Zhang, Ce and Vechev, Martin T.},
	year = {2019},
	pages = {1931--1941},
}

@inproceedings{wang_satnet_2019,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {{SATNet}: {Bridging} deep learning and logical reasoning using a differentiable satisfiability solver},
	volume = {97},
	booktitle = {{ICML}},
	publisher = {PMLR},
	author = {Wang, Po-Wei and Donti, Priya L. and Wilder, Bryan and Kolter, J. Zico},
	year = {2019},
	pages = {6545--6554},
}

@article{kusiak_convolutional_2020-1,
	title = {Convolutional and generative adversarial neural networks in manufacturing},
	volume = {58},
	number = {5},
	journal = {Int. J. Prod. Res.},
	author = {Kusiak, Andrew},
	year = {2020},
	pages = {1594--1604},
}

@article{alam_gencad_2025,
	title = {{GenCAD}: {Image}-{Conditioned} {Computer}-{Aided} {Design} {Generation} with {Transformer}-{Based} {Contrastive} {Representation} and {Diffusion} {Priors}},
	journal = {Trans. M.L. Res.},
	author = {Alam, Md Ferdous and Ahmed, Faez},
	year = {2025},
}

@inproceedings{li_caddreamer_2025,
	title = {{CADDreamer}: {CAD} {Object} {Generation} from {Single}-view {Images}},
	booktitle = {{CVPR}},
	publisher = {CVF / IEEE},
	author = {Li, Yuan and Lin, Cheng and Liu, Yuan and others, and},
	year = {2025},
	pages = {21448--21457},
}

@article{cuomo_scientific_2022-1,
	title = {Scientific {Machine} {Learning} {Through} {Physics}-{Informed} {Neural} {Networks}: {Where} we are and {What}'s {Next}},
	volume = {92},
	number = {3},
	journal = {J. Sci. Comput.},
	author = {Cuomo, Salvatore and Cola, Vincenzo Schiano Di and Giampaolo, Fabio and Rozza, Gianluigi and Raissi, Maziar and Piccialli, Francesco},
	year = {2022},
	pages = {88},
}

@article{kautz_third_2022-1,
	title = {The {Third} {AI} {Summer}: {AAAI} {Robert} {S}. {Engelmore} {Memorial} {Lecture}},
	volume = {43},
	number = {1},
	journal = {AI Mag.},
	author = {Kautz, Henry A.},
	year = {2022},
	pages = {93--104},
}

@article{singh_benchmarking_2025,
	title = {Benchmarking {Neurosymbolic} {Description} {Logic} {Reasoners}: {Existing} {Challenges} and a {Way} {Forward}},
	volume = {1},
	issn = {2949-8732},
	journal = {NeSy Art. Int.},
	author = {Singh, Gunjan and Tommasini, Riccardo and Bhatia, Sumit and Mutharaju, Raghava},
	year = {2025},
}

@inproceedings{bortolotti_neuro-symbolic_2024,
	title = {A {Neuro}-{Symbolic} {Benchmark} {Suite} for {Concept} {Quality} and {Reasoning} {Shortcuts}},
	booktitle = {{NeurIPS}},
	author = {Bortolotti, Samuele and Marconato, Emanuele and Carraro, Tommaso and Morettin, Paolo and others, and},
	year = {2024},
}

@article{arachchige_roadmap_2025,
	title = {A {Roadmap} {Toward} {Neurosymbolic} {Approaches} in {AI} {Design}},
	volume = {13},
	journal = {IEEE Access},
	author = {Arachchige, Prashani Jayasingha and Iancu, Bogdan and Lilius, Johan},
	year = {2025},
	pages = {174368--174392},
}

@inproceedings{reymond_pareto_2022,
	title = {Pareto {Conditioned} {Networks}},
	booktitle = {{AAMAS}},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)},
	author = {Reymond, Mathieu and Bargiacchi, Eugenio and Nowé, Ann},
	year = {2022},
}

@inproceedings{pfisterer_yahpo_2022,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {{YAHPO} {Gym} - {An} {Efficient} {Multi}-{Objective} {Multi}-{Fidelity} {Benchmark} for {Hyperparameter} {Optimization}},
	volume = {188},
	booktitle = {{AutoML}},
	publisher = {PMLR},
	author = {Pfisterer, Florian and Schneider, Lennart and Moosbauer, Julia and Binder, Martin and Bischl, Bernd},
	year = {2022},
	pages = {3/1--39},
}

@inproceedings{colelough_neuro-symbolic_2024,
	series = {{CEUR} {Workshop} {Proceedings}},
	title = {Neuro-{Symbolic} {AI} in 2024: {A} {Systematic} {Review}},
	volume = {3819},
	booktitle = {{LNSAI}@{IJCAI}},
	publisher = {CEUR-WS.org},
	author = {Colelough, Brandon Curtis and Regli, William},
	year = {2024},
}

@inproceedings{yang_preference_2025,
	title = {Preference {Controllable} {Reinforcement} {Learning} with {Advanced} {Multi}-{Objective} {Optimization}},
	booktitle = {Forty-second {International} {Conference} on {Machine} {Learning}},
	author = {Yang, Yucheng and Zhou, Tianyi and Pechenizkiy, Mykola and Fang, Meng},
	year = {2025},
}

@article{regenwetter_beyond_2023,
	title = {Beyond {Statistical} {Similarity}: {Rethinking} {Metrics} for {Deep} {Generative} {Models} in {Engineering} {Design}},
	volume = {165},
	journal = {Comput. Aided Des.},
	author = {Regenwetter, Lyle and Srivastava, Akash and Gutfreund, Dan and Ahmed, Faez},
	year = {2023},
}

@inproceedings{bougzime_evaluating_2025,
	title = {Evaluating {Neuro}-{Symbolic} {AI} {Architectures}: {Design} {Principles}, {Qualitative} {Benchmark}, {Comparative} {Analysis} and {Results}},
	booktitle = {19th {Intern}. {Conf}. on {NeuSy} {Learn}. and {Reas}.},
	author = {Bougzime, Oualid and JABBAR, Samir and Cruz, Christophe and Demoly, Frédéric},
	year = {2025},
}

@article{willis_fusion_2021,
	title = {Fusion 360 gallery: a dataset and environment for programmatic {CAD} construction from human design sequences},
	volume = {40},
	number = {4},
	journal = {ACM Trans. Graph.},
	author = {Willis, Karl D. D. and Pu, Yewen and Luo, Jieliang and {others}},
	year = {2021},
	pages = {54:1--54:24},
}

@article{seff_sketchgraphs_2020,
	title = {{SketchGraphs}: {A} {Large}-{Scale} {Dataset} for {Modeling} {Relational} {Geometry} in {Computer}-{Aided} {Design}},
	volume = {abs/2007.08506},
	journal = {CoRR},
	author = {Seff, Ari and Ovadia, Yaniv and Zhou, Wenda and Adams, Ryan P.},
	year = {2020},
}

@article{bougzime_neuro-symbolic_2025,
	title = {Neuro-symbolic artificial intelligence in accelerated design for {4D} printing: {Status}, challenges, and perspectives},
	volume = {252},
	issn = {0264-1275},
	journal = {Materials \& Design},
	author = {Bougzime, Oualid and Cruz, Christophe and André, Jean-Claude and Zhou, Kun and Qi, H. Jerry and Demoly, Frédéric},
	year = {2025},
	pages = {113737},
}

@article{khanmohamadi_advanced_2024,
	title = {Advanced {Sensor} {Technologies} in {CAVs} for {Traditional} and {Smart} {Road} {Condition} {Monitoring}: {A} {Review}},
	volume = {16},
	journal = {Sustainability},
	author = {Khanmohamadi, Masoud and Guerrieri, Marco},
	year = {2024},
}

@inproceedings{jalaian_neurosymbolic_2023,
	title = {Neurosymbolic {AI} in {Cybersecurity}: {Bridging} {Pattern} {Recognition} and {Symbolic} {Reasoning}},
	booktitle = {{MILCOM}},
	publisher = {IEEE},
	author = {Jalaian, Brian and Bastian, Nathaniel D.},
	year = {2023},
	pages = {268--273},
}

@inproceedings{collins_abo_2022-1,
	address = {New Orleans, LA, USA},
	title = {{ABO}: {Dataset} and {Benchmarks} for {Real}-{World} {3D} {Object} {Understanding}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-6654-6946-3},
	shorttitle = {{ABO}},
	url = {https://ieeexplore.ieee.org/document/9879101/},
	doi = {10.1109/CVPR52688.2022.02045},
	abstract = {We introduce Amazon Berkeley Objects (ABO), a new large-scale dataset designed to help bridge the gap between real and virtual 3D worlds. ABO contains product catalog images, metadata, and artist-created 3D models with complex geometries and physically-based materials that correspond to real, household objects. We derive challenging benchmarks that exploit the unique properties of ABO and measure the current limits of the state-of-the-art on three open problems for real-world 3D object understanding: single-view 3D reconstruction, material estimation, and cross-domain multi-view object retrieval.},
	language = {en},
	urldate = {2026-01-21},
	booktitle = {2022 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Collins, Jasmine and Goel, Shubham and Deng, Kenan and Luthra, Achleshwar and Xu, Leon and Gundogdu, Erhan and Zhang, Xi and Vicente, Tomas F. Yago and Dideriksen, Thomas and Arora, Himanshu and Guillaumin, Matthieu and Malik, Jitendra},
	month = jun,
	year = {2022},
	pages = {21094--21104},
}

@misc{xu_adaptive_2025-1,
	title = {Adaptive {LLM}-{Symbolic} {Reasoning} via {Dynamic} {Logical} {Solver} {Composition}},
	url = {http://arxiv.org/abs/2510.06774},
	doi = {10.48550/arXiv.2510.06774},
	abstract = {Neuro-symbolic NLP methods aim to leverage the complementary strengths of large language models and formal logical solvers. However, current approaches are mostly static in nature, i.e., the integration of a target solver is predetermined at design time, hindering the ability to employ diverse formal inference strategies. To address this, we introduce an adaptive, multi-paradigm, neuro-symbolic inference framework that: (1) automatically identifies formal reasoning strategies from problems expressed in natural language; and (2) dynamically selects and applies specialized formal logical solvers via autoformalization interfaces. Extensive experiments on individual and multi-paradigm reasoning tasks support the following conclusions: LLMs are effective at predicting the necessary formal reasoning strategies with an accuracy above 90 percent. This enables flexible integration with formal logical solvers, resulting in our framework outperforming competing baselines by 27 percent and 6 percent compared to GPT-4o and DeepSeek-V3.1, respectively. Moreover, adaptive reasoning can even positively impact pure LLM methods, yielding gains of 10, 5, and 6 percent on zero-shot, CoT, and symbolic CoT settings with GPT-4o. Finally, although smaller models struggle with adaptive neuro-symbolic reasoning, post-training offers a viable path to improvement. Overall, this work establishes the foundations for adaptive LLM-symbolic reasoning, offering a path forward for unifying material and formal inferences on heterogeneous reasoning challenges.},
	urldate = {2026-01-21},
	publisher = {arXiv},
	author = {Xu, Lei and Beckmann, Pierre and Valentino, Marco and Freitas, André},
	month = oct,
	year = {2025},
	note = {arXiv:2510.06774 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@article{renkhoff_survey_2024-1,
	title = {A {Survey} on {Verification} and {Validation}, {Testing} and {Evaluations} of {Neurosymbolic} {Artificial} {Intelligence}},
	volume = {5},
	issn = {2691-4581},
	url = {https://ieeexplore.ieee.org/document/10385139/},
	doi = {10.1109/TAI.2024.3351798},
	abstract = {Neurosymbolic artificial intelligence (AI) is an emerging branch of AI that combines the strengths of symbolic AI and subsymbolic AI. Symbolic AI is based on the idea that intelligence can be represented using semantically meaningful symbolic rules and representations, while deep learning (DL), or sometimes called subsymbolic AI, is based on the idea that intelligence emerges from the collective behavior of artificial neurons that are connected to each other. A major drawback of DL is that it acts as a “black box,” meaning that predictions are difficult to explain, making the testing \& evaluation (T\&E); validation \& verification (V\&V) processes of a system that uses subsymbolic AI a challenge. Since neurosymbolic AI combines the advantages of both symbolic and subsymbolic AI, this survey explores how neurosymbolic applications can ease the V\&V process. This survey considers two taxonomies of neurosymbolic AI, evaluates them, and analyzes which algorithms are commonly used as the symbolic and subsymbolic components in current applications. Additionally, an overview of current techniques for the T\&e; V\&V processes of these components is provided. Furthermore, it is investigated how the symbolic part is used for T\&e; V\&V purposes in current neurosymbolic applications. Our research shows that neurosymbolic AI has great potential to ease the T\&e; V\&V processes of subsymbolic AI by leveraging the possibilities of symbolic AI. Additionally, the applicability of current T\&e; V\&V methods to neurosymbolic AI is assessed, and how different neurosymbolic architectures can impact these methods is explored. It is found that current T\&e; V\&V techniques are partly sufficient to test, evaluate, verify, or validate the symbolic and subsymbolic part of neurosymbolic applications independently, while some of them use approaches where current T\&e; V\&V methods are not applicable by default, and adjustments or even new approaches are needed. Our research shows that there is great potential in using symbolic AI to test, evaluate, verify, or validate the predictions of a subsymbolic model, making neurosymbolic AI an interesting research direction for safe, secure, and trustworthy AI.},
	number = {8},
	urldate = {2026-01-21},
	journal = {IEEE Transactions on Artificial Intelligence},
	author = {Renkhoff, Justus and Feng, Ke and Meier-Doernberg, Marc and Velasquez, Alvaro and Song, Houbing Herbert},
	month = aug,
	year = {2024},
	keywords = {Neural networks, Testing, Computer architecture, Surveys, Task analysis, Artificial intelligence, Deep learning (DL), evaluation, neurosymbolic artificial intelligence (AI), safety, security, Taxonomy, testing, trustworthiness, validation, verification},
	pages = {3765--3779},
}

@article{arachchige_roadmap_2025-1,
	title = {A {Roadmap} {Toward} {Neurosymbolic} {Approaches} in {AI} {Design}},
	volume = {13},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/11192262},
	doi = {10.1109/ACCESS.2025.3617771},
	abstract = {Neurosymbolic Artificial Intelligence (NeSy) integrates two central paradigms in artificial intelligence (AI). The first is connectionist (or sub-symbolic) AI, which enables scalable and efficient statistical learning. The second is symbolic reasoning, which provides formal reasoning and explainability. This study conducted a systematic review of NeSy architectures published between 2013 and 2024, synthesizing the structural patterns and integration strategies from 319 peer-reviewed publications. From this corpus, 18 representative approaches were selected based on methodological rigor, symbolic fidelity, and conceptual novelty. These approaches were subsequently classified into three architectural paradigms: Sequential, Multi-Integration, and Hybrid. Based on this classification, a five-stage symbolic integration framework is proposed, comprising 1) data preprocessing, 2) neural–symbolic embedding, 3) incorporation of domain knowledge, 4) logical reasoning modules, and 5) symbolic postprocessing. The findings indicate that multistage symbolic integration, particularly when embedded within neural layers and reasoning components, improves the system’s explainability, robustness, and semantic alignment. Comparative analysis further reveals a fundamental trade-off: architectures grounded in formal logic exhibit higher precision and verifiability, whereas those employing representational-symbolic languages yield greater interpretability and flexibility. The resulting generic architecture provides a modular design blueprint for future NeSy systems, supporting scalable, transparent, and semantically grounded AI development.},
	urldate = {2026-01-21},
	journal = {IEEE Access},
	author = {Arachchige, Prashani Jayasingha and Iancu, Bogdan and Lilius, Johan},
	year = {2025},
	keywords = {Neural networks, Cognition, Transformers, Computer architecture, Artificial intelligence, Neurosymbolic AI, Guidelines, Systematic literature review, NeSy, Problem-solving, Self-organizing feature maps, Semantics, sub-symbolic AI, symbolic AI},
	pages = {174368--174392},
}

@article{novelli_accountability_2024-1,
	title = {Accountability in artificial intelligence: what it is and how it works},
	volume = {39},
	issn = {1435-5655},
	shorttitle = {Accountability in artificial intelligence},
	url = {https://doi.org/10.1007/s00146-023-01635-y},
	doi = {10.1007/s00146-023-01635-y},
	abstract = {Accountability is a cornerstone of the governance of artificial intelligence (AI). However, it is often defined too imprecisely because its multifaceted nature and the sociotechnical structure of AI systems imply a variety of values, practices, and measures to which accountability in AI can refer. We address this lack of clarity by defining accountability in terms of answerability, identifying three conditions of possibility (authority recognition, interrogation, and limitation of power), and an architecture of seven features (context, range, agent, forum, standards, process, and implications). We analyze this architecture through four accountability goals (compliance, report, oversight, and enforcement). We argue that these goals are often complementary and that policy-makers emphasize or prioritize some over others depending on the proactive or reactive use of accountability and the missions of AI governance.},
	language = {en},
	number = {4},
	urldate = {2026-01-21},
	journal = {AI \& Soc},
	author = {Novelli, Claudio and Taddeo, Mariarosaria and Floridi, Luciano},
	month = aug,
	year = {2024},
	keywords = {Artificial intelligence, Accountability, AI Act, Governance, Policy},
	pages = {1871--1882},
}

@article{li_ontology-based_2018-1,
	title = {An ontology-based product design framework for manufacturability verification and knowledge reuse},
	volume = {99},
	copyright = {2018 Springer-Verlag London Ltd., part of Springer Nature},
	issn = {1433-3015},
	url = {https://link.springer.com/article/10.1007/s00170-018-2099-2},
	doi = {10.1007/s00170-018-2099-2},
	abstract = {To achieve efficient development of high-quality product, manufacturing constraints must be fully taken into account at the early design stage. However, designers lack in-depth knowledge of manufacturing and production. Many time-consuming iterations of design changes are required between designers and manufacturing engineers. In order to minimize this knowledge gap, this paper presents an ontology-based product design framework for manufacturability verification and knowledge reuse to support the sharing and reuse of design and manufacturing knowledge. It aims at providing advices and feedback of restraints of manufacturing processes to the designers during the design process. The proposed framework consists of three major layers which include a foundation layer, a domain layer, and an instance layer. We use the Web Ontology Language (OWL), a standard of ontology representation language, to formalize the foundation layer. It contains the core product model and the standard ISO 10303 AP224 application protocol. The domain layer comprises extensional concepts and relationships for design and manufacturing integration and a rule base for manufacturability verification, which is represented in Semantic Web Rule Language (SWRL). In the instance layer, an inference engine is developed based on ontology and rule inference. It provides recommendations of manufacturability. Two case studies are provided as application examples to demonstrate the effectiveness of the framework.},
	language = {En},
	number = {9},
	urldate = {2026-01-21},
	journal = {The International Journal of Advanced Manufacturing Technology},
	publisher = {Springer},
	author = {Li, Zhi and Zhou, Xiaowu and Wang, W. M. and Huang, George and Tian, Zonggui and Huang, Shaowei},
	month = may,
	year = {2018},
	pages = {2121--2135},
}

@inproceedings{wu_cadvlm_2025,
	address = {Cham},
	title = {{CadVLM}: {Bridging} {Language} and {Vision} in the {Generation} of {Parametric} {CAD} {Sketches}},
	isbn = {978-3-031-72897-6},
	shorttitle = {{CadVLM}},
	doi = {10.1007/978-3-031-72897-6_21},
	abstract = {Parametric Computer-Aided Design (CAD) is central to contemporary mechanical design. However, it encounters challenges in achieving precise parametric sketch modeling and lacks practical evaluation metrics suitable for mechanical design. We harness the capabilities of pre-trained foundation models, renowned for their successes in natural language processing and computer vision, to develop generative models specifically for CAD. These models are adept at understanding complex geometries and design reasoning, a crucial advancement in CAD technology. In this paper, we propose CadVLM, an end-to-end vision language model for CAD generation. Our approach involves adapting pre-trained foundation models to manipulate engineering sketches effectively, integrating both sketch primitive sequences and sketch images. Extensive experiments demonstrate superior performance on multiple CAD sketch generation tasks such as CAD autocompletion, CAD autoconstraint, and image conditional generation. To our knowledge, this is the first instance of a multimodal Large Language Model (LLM) being successfully applied to parametric CAD generation, representing a pioneering step in the field of computer-aided mechanical design.},
	language = {en},
	booktitle = {Computer {Vision} – {ECCV} 2024},
	publisher = {Springer Nature Switzerland},
	author = {Wu, Sifan and Khasahmadi, Amir Hosein and Katz, Mor and Jayaraman, Pradeep Kumar and Pu, Yewen and Willis, Karl and Liu, Bang},
	editor = {Leonardis, Aleš and Ricci, Elisa and Roth, Stefan and Russakovsky, Olga and Sattler, Torsten and Varol, Gül},
	year = {2025},
	keywords = {CAD Representation, Vision languge model},
	pages = {368--384},
}

@article{li_caddreamer_nodate,
	title = {{CADDreamer}: {CAD} {Object} {Generation} from {Single}-view {Images}},
	language = {en},
	author = {Li, Yuan and Lin, Cheng and Liu, Yuan and Long, Xiaoxiao and Zhang, Chenxu and Wang, Ningna and Li, Xin and Wang, Wenping and Guo, Xiaohu},
}

@inproceedings{luo_archcad-400k_2025-1,
	title = {{ArchCAD}-{400K}: {A} {Large}-{Scale} {CAD} drawings {Dataset} and {New} {Baseline} for {Panoptic} {Symbol} {Spotting}},
	shorttitle = {{ArchCAD}-{400K}},
	url = {https://openreview.net/forum?id=rAGWvnpcKe&referrer=%5Bthe%20profile%20of%20Ruifeng%20Luo%5D(%2Fprofile%3Fid%3D~Ruifeng_Luo3)},
	abstract = {Recognizing symbols in architectural CAD drawings is critical for various advanced engineering applications. In this paper, we propose a novel CAD data annotation engine that leverages intrinsic attributes from systematically archived CAD drawings to automatically generate high-quality annotations, thus significantly reducing manual labeling efforts. Utilizing this engine, we construct ArchCAD-400K, a large-scale CAD dataset consisting of 413,062 chunks from 5538 highly standardized drawings, making it over 26 times larger than the largest existing CAD dataset. ArchCAD-400K boasts an extended drawing diversity and broader categories, offering line-grained annotations. Furthermore, we present a new baseline model for panoptic symbol spotting, termed Dual-Pathway Symbol Spotter (DPSS). It incorporates an adaptive fusion module to enhance primitive features with complementary image features, achieving state-of-the-art performance and enhanced robustness. Extensive experiments validate the effectiveness of DPSS, demonstrating the value of ArchCAD-400K and its potential to drive innovation in architectural design and construction.},
	language = {en},
	urldate = {2026-01-21},
	author = {Luo, Ruifeng and Liu, Zhengjie and Cheng, Tianxiao and Wang, Jie and Wang, Tongjie and Cheng, Fei and Chai, Fu and Li, Yanpeng and Wei, Xingguang and Wang, Haomin and Ye, Shenglong and Wang, Wenhai and Zhang, Yanting and Qiao, Yu and Zhang, Hongjie and Zhao, Xianzhong},
	month = oct,
	year = {2025},
}

@misc{noauthor_benchmarking_nodate,
	title = {Benchmarking {Neuro}-{Symbolic} {Description} {Logic} {Reasoners}: {Existing} {Challenges} and {A} {Way} {Forward} {\textbar} {Neurosymbolic} {Artificial} {Intelligence}},
	url = {https://neurosymbolic-ai-journal.com/paper/benchmarking-neuro-symbolic-description-logic-reasoners-existing-challenges-and-way-forward},
	urldate = {2026-01-21},
	}

@article{alam_gencad_2024,
	title = {{GenCAD}: {Image}-{Conditioned} {Computer}-{Aided} {Design} {Generation} with {Transformer}-{Based} {Contrastive} {Representation} and {Diffusion} {Priors}},
	issn = {2835-8856},
	shorttitle = {{GenCAD}},
	url = {https://openreview.net/forum?id=e817c1wEZ6},
	abstract = {The creation of manufacturable and editable 3D shapes through Computer-Aided Design (CAD) remains a highly manual and time-consuming task, hampered by the complex topology of boundary representations of 3D solids and unintuitive design tools. While most work in the 3D shape generation literature focuses on representations like meshes, voxels, or point clouds, practical engineering applications demand the modifiability and manufacturability of CAD models and the ability for multi-modal conditional CAD model generation. This paper introduces GenCAD, a generative model that employs autoregressive transformers with a contrastive learning framework and latent diffusion models to transform image inputs into parametric CAD command sequences, resulting in editable 3D shape representations. Extensive evaluations demonstrate that GenCAD significantly outperforms existing state-of-the-art methods in terms of the unconditional and conditional generations of CAD models. Additionally, the contrastive learning framework of GenCAD facilitates the retrieval of CAD models using image queries from large CAD databases, which is a critical challenge within the CAD community. Our results provide a significant step forward in highlighting the potential of generative models to expedite the entire design-to-production pipeline and seamlessly integrate different design modalities.},
	language = {en},
	urldate = {2026-01-21},
	journal = {Transactions on Machine Learning Research},
	author = {Alam, Md Ferdous and Ahmed, Faez},
	month = sep,
	year = {2024},
}

@article{heidari_geometric_2025,
	title = {Geometric {Deep} {Learning} for {Computer}-{Aided} {Design}: {A} {Survey}},
	volume = {13},
	issn = {2169-3536},
	shorttitle = {Geometric {Deep} {Learning} for {Computer}-{Aided} {Design}},
	url = {https://ieeexplore.ieee.org/document/11075586/},
	doi = {10.1109/ACCESS.2025.3587121},
	abstract = {Geometric Deep Learning techniques have become a transformative force in the field of Computer-Aided Design (CAD), and have the potential to revolutionize how designers and engineers approach and enhance the design process. By harnessing the power of machine learning-based methods, CAD designers can optimize their workflows, save time and effort while making better informed decisions, and create designs that are both innovative and practical. The ability to process the CAD designs represented by geometric data and to analyze their encoded features enables the identification of similarities among diverse CAD models, the proposition of alternative designs and enhancements, and even the generation of novel design alternatives. This survey offers a comprehensive overview of learning-based methods in computer-aided design across various categories, including similarity analysis and retrieval, 2D and 3D CAD model synthesis, and CAD generation from point clouds, and single/multi-view images. Additionally, it provides a complete list of benchmark datasets and their characteristics, along with open-source codes that have propelled research in this domain. The final discussion delves into the challenges prevalent in this field, followed by potential future research directions in this rapidly evolving field.},
	urldate = {2026-01-21},
	journal = {IEEE Access},
	author = {Heidari, Negar and Iosifidis, Alexandros},
	year = {2025},
	keywords = {Deep learning, Analytical models, Surveys, machine learning, Data models, graph neural networks, Shape, Solid modeling, Three-dimensional displays, Computer-aided design, Design automation, geometric deep learning, Python, Software},
	pages = {119305--119334},
}

@article{heidari_geometric_2025-1,
	title = {Geometric {Deep} {Learning} for {Computer}-{Aided} {Design}: {A} {Survey}},
	volume = {13},
	issn = {2169-3536},
	shorttitle = {Geometric {Deep} {Learning} for {Computer}-{Aided} {Design}},
	url = {https://ieeexplore.ieee.org/document/11075586/},
	doi = {10.1109/ACCESS.2025.3587121},
	abstract = {Geometric Deep Learning techniques have become a transformative force in the field of Computer-Aided Design (CAD), and have the potential to revolutionize how designers and engineers approach and enhance the design process. By harnessing the power of machine learning-based methods, CAD designers can optimize their workflows, save time and effort while making better informed decisions, and create designs that are both innovative and practical. The ability to process the CAD designs represented by geometric data and to analyze their encoded features enables the identification of similarities among diverse CAD models, the proposition of alternative designs and enhancements, and even the generation of novel design alternatives. This survey offers a comprehensive overview of learning-based methods in computer-aided design across various categories, including similarity analysis and retrieval, 2D and 3D CAD model synthesis, and CAD generation from point clouds, and single/multi-view images. Additionally, it provides a complete list of benchmark datasets and their characteristics, along with open-source codes that have propelled research in this domain. The final discussion delves into the challenges prevalent in this field, followed by potential future research directions in this rapidly evolving field.},
	urldate = {2026-01-21},
	journal = {IEEE Access},
	author = {Heidari, Negar and Iosifidis, Alexandros},
	year = {2025},
	keywords = {Deep learning, Analytical models, Surveys, machine learning, Data models, graph neural networks, Shape, Solid modeling, Three-dimensional displays, Computer-aided design, Design automation, geometric deep learning, Python, Software},
	pages = {119305--119334},
}

@misc{niu_pht-cad_2025-1,
	title = {{PHT}-{CAD}: {Efficient} {CAD} {Parametric} {Primitive} {Analysis} with {Progressive} {Hierarchical} {Tuning}},
	shorttitle = {{PHT}-{CAD}},
	url = {http://arxiv.org/abs/2503.18147},
	doi = {10.48550/arXiv.2503.18147},
	abstract = {Computer-Aided Design (CAD) plays a pivotal role in industrial manufacturing, yet 2D Parametric Primitive Analysis (PPA) remains underexplored due to two key challenges: structural constraint reasoning and advanced semantic understanding. To tackle these challenges, we first propose an Efficient Hybrid Parametrization (EHP) for better representing 2D engineering drawings. EHP contains four types of atomic component i.e., point, line, circle, and arc). Additionally, we propose PHT-CAD, a novel 2D PPA framework that harnesses the modality alignment and reasoning capabilities of Vision-Language Models (VLMs) for precise engineering drawing analysis. In PHT-CAD, we introduce four dedicated regression heads to predict corresponding atomic components. To train PHT-CAD, a three-stage training paradigm Progressive Hierarchical Tuning (PHT) is proposed to progressively enhance PHT-CAD's capability to perceive individual primitives, infer structural constraints, and align annotation layers with their corresponding geometric representations. Considering that existing datasets lack complete annotation layers and real-world engineering drawings, we introduce ParaCAD, the first large-scale benchmark that explicitly integrates both the geometric and annotation layers. ParaCAD comprises over 10 million annotated drawings for training and 3,000 real-world industrial drawings with complex topological structures and physical constraints for test. Extensive experiments demonstrate the effectiveness of PHT-CAD and highlight the practical significance of ParaCAD in advancing 2D PPA research.},
	urldate = {2026-01-21},
	publisher = {arXiv},
	author = {Niu, Ke and Chen, Yuwen and Yu, Haiyang and Chen, Zhuofan and Que, Xianghui and Li, Bin and Xue, Xiangyang},
	month = may,
	year = {2025},
	note = {arXiv:2503.18147 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{wang_satnet_2019-1,
	title = {{SATNet}: {Bridging} deep learning and logical reasoning using a differentiable satisfiability solver},
	issn = {2640-3498},
	shorttitle = {{SATNet}},
	url = {https://proceedings.mlr.press/v97/wang19e.html},
	abstract = {Integrating logical reasoning within deep learning architectures has been a major goal of modern AI systems. In this paper, we propose a new direction toward this goal by introducing a differentiable (smoothed) maximum satisfiability (MAXSAT) solver that can be integrated into the loop of larger deep learning systems. Our (approximate) solver is based upon a fast coordinate descent approach to solving the semidefinite program (SDP) associated with the MAXSAT problem. We show how to analytically differentiate through the solution to this SDP and efficiently solve the associated backward pass. We demonstrate that by integrating this solver into end-to-end learning systems, we can learn the logical structure of challenging problems in a minimally supervised fashion. In particular, we show that we can learn the parity function using single-bit supervision (a traditionally hard task for deep networks) and learn how to play 9x9 Sudoku solely from examples. We also solve a “visual Sudoku” problem that maps images of Sudoku puzzles to their associated logical solutions by combining our MAXSAT solver with a traditional convolutional architecture. Our approach thus shows promise in integrating logical structures within deep learning.},
	language = {en},
	urldate = {2026-01-21},
	booktitle = {Proceedings of the 36th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Wang, Po-Wei and Donti, Priya and Wilder, Bryan and Kolter, Zico},
	month = may,
	year = {2019},
	pages = {6545--6554},
}

@misc{seff_sketchgraphs_2020-1,
	title = {{SketchGraphs}: {A} {Large}-{Scale} {Dataset} for {Modeling} {Relational} {Geometry} in {Computer}-{Aided} {Design}},
	shorttitle = {{SketchGraphs}},
	url = {http://arxiv.org/abs/2007.08506},
	doi = {10.48550/arXiv.2007.08506},
	abstract = {Parametric computer-aided design (CAD) is the dominant paradigm in mechanical engineering for physical design. Distinguished by relational geometry, parametric CAD models begin as two-dimensional sketches consisting of geometric primitives (e.g., line segments, arcs) and explicit constraints between them (e.g., coincidence, perpendicularity) that form the basis for three-dimensional construction operations. Training machine learning models to reason about and synthesize parametric CAD designs has the potential to reduce design time and enable new design workﬂows. Additionally, parametric CAD designs can be viewed as instances of constraint programming and they offer a well-scoped test bed for exploring ideas in program synthesis and induction. To facilitate this research, we introduce SketchGraphs, a collection of 15 million sketches extracted from real-world CAD models coupled with an open-source data processing pipeline. Each sketch is represented as a geometric constraint graph where edges denote designer-imposed geometric relationships between primitives, the nodes of the graph. We demonstrate and establish benchmarks for two use cases of the dataset: generative modeling of sketches and conditional generation of likely constraints given unconstrained geometry.},
	language = {en},
	urldate = {2026-01-21},
	publisher = {arXiv},
	author = {Seff, Ari and Ovadia, Yaniv and Zhou, Wenda and Adams, Ryan P.},
	month = jul,
	year = {2020},
	note = {arXiv:2007.08506 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{lehrer_ucsm_2025-1,
	title = {{UCSM}: {Dataset} of {U}-shaped parametric {CAD} geometries and real-world sheet metal meshes for deep drawing},
	volume = {188},
	issn = {0010-4485},
	shorttitle = {{UCSM}},
	url = {https://www.sciencedirect.com/science/article/pii/S0010448525000855},
	doi = {10.1016/j.cad.2025.103924},
	abstract = {The development of machine learning (ML) applications in deep drawing is hindered by limited data availability and the absence of open-access benchmarks for validating novel approaches, including domain generalization over distinct geometries. This paper addresses these challenges by introducing a comprehensive U-shaped dataset tailored to this manufacturing process. Our U-Channel sheet metal (UCSM) dataset combines 90 real-world meshes with an infinite number of synthetic geometry samples generated from four parametric Computer-Aided Design (CAD) models, ensuring extensive geometry variety and data quantity. Additionally, a ready-to-use dataset for drawability assessment and segmentation is provided. Leveraging CAD and mesh data sources bridges the gap between sparse data availability and ML requirements. Our analysis demonstrates that the proposed parametric models are geometrically valid, and real-world and synthetic data complement each other effectively, providing robust support for ML model development. While the dataset is confined to U-shaped, thin-walled, deep drawing scenarios, it considerably aids in overcoming data scarcity. Thereby, it facilitates the validation and comparison of new geometry-generalizing ML methodologies in this domain. By providing this benchmark dataset, we enhance the comparability and validation of emerging methods for ML advancements in sheet metal forming.},
	urldate = {2026-01-21},
	journal = {Computer-Aided Design},
	author = {Lehrer, Tobias and Stocker, Philipp and Duddeck, Fabian and Wagner, Marcus},
	month = nov,
	year = {2025},
	keywords = {Machine learning, Benchmark dataset, Computer-Aided Design, Domain generalization, Parametric CAD models, U-channel},
	pages = {103924},
}

@inproceedings{pfisterer_yahpo_2022-1,
	title = {{YAHPO} {Gym} - {An} {Efficient} {Multi}-{Objective} {Multi}-{Fidelity} {Benchmark} for {Hyperparameter} {Optimization}},
	issn = {2640-3498},
	url = {https://proceedings.mlr.press/v188/pfisterer22a.html},
	abstract = {When developing and analyzing new hyperparameter optimization methods, it is vital to empirically evaluate and compare them on well-curated benchmark suites. In this work, we propose a new set of challenging and relevant benchmark problems motivated by desirable properties and requirements for such benchmarks. Our new surrogate-based benchmark collection consists of 14 scenarios that in total constitute over 700 multi-fidelity hyperparameter optimization problems, which all enable multi-objective hyperparameter optimization. Furthermore, we empirically compare surrogate-based benchmarks to the more widely-used tabular benchmarks, and demonstrate that the latter may produce unfaithful results regarding the performance ranking of HPO methods. We examine and compare our benchmark collection with respect to defined requirements and propose a single-objective as well as a multi-objective benchmark suite on which we compare 7 single-objective and 7 multi-objective optimizers in a benchmark experiment.  Our software is available at {\textbackslash}url\{https://github.com/slds-lmu/yahpo\_gym\}.},
	language = {en},
	urldate = {2026-01-21},
	booktitle = {Proceedings of the {First} {International} {Conference} on {Automated} {Machine} {Learning}},
	publisher = {PMLR},
	author = {Pfisterer, Florian and Schneider, Lennart and Moosbauer, Julia and Binder, Martin and Bischl, Bernd},
	month = sep,
	year = {2022},
	pages = {3/1--39},
}
